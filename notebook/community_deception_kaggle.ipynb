{"metadata":{"colab":{"collapsed_sections":["_roZ5e0G-dkp"],"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6540108,"sourceType":"datasetVersion","datasetId":3759485},{"sourceId":7059200,"sourceType":"datasetVersion","datasetId":3578362}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Community Deception","metadata":{"id":"p0PM-10o4qNq"}},{"cell_type":"markdown","source":"Only for `colab` notebook.","metadata":{"id":"CgIFIlS1Kz3U"}},{"cell_type":"code","source":"# ONLY FOR COLAB\n# from google.colab import drive\n# drive.mount(\"/content/gdrive\")","metadata":{"id":"e3GbJlMnKz3V","outputId":"ca6b944b-375a-4932-81cf-f91044075ba3","execution":{"iopub.status.busy":"2023-12-01T07:04:18.835177Z","iopub.execute_input":"2023-12-01T07:04:18.835644Z","iopub.status.idle":"2023-12-01T07:04:18.867199Z","shell.execute_reply.started":"2023-12-01T07:04:18.835597Z","shell.execute_reply":"2023-12-01T07:04:18.866114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ONLY FOR COLAB\n# import os\n# os.chdir(\"/content/gdrive/MyDrive/Sapienza/Tesi/community_deception_large_graphs\")","metadata":{"id":"6NEkTwS5Kz3W","execution":{"iopub.status.busy":"2023-12-01T07:04:18.868949Z","iopub.execute_input":"2023-12-01T07:04:18.870169Z","iopub.status.idle":"2023-12-01T07:04:18.875292Z","shell.execute_reply.started":"2023-12-01T07:04:18.870093Z","shell.execute_reply":"2023-12-01T07:04:18.874335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install Dependencies","metadata":{"id":"VVg01dhnKz3X"}},{"cell_type":"code","source":"! pip install torchvision torchaudio igraph \"cdlib[C]\" karateclub","metadata":{"id":"roRqhVQMKz3X","outputId":"85a358d3-8c8d-4525-95ca-bf7271dd5f57","execution":{"iopub.status.busy":"2023-12-01T07:04:18.876516Z","iopub.execute_input":"2023-12-01T07:04:18.877425Z","iopub.status.idle":"2023-12-01T07:11:24.030265Z","shell.execute_reply.started":"2023-12-01T07:04:18.877389Z","shell.execute_reply":"2023-12-01T07:11:24.028586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! pip install numpy pandas scipy networkx matplotlib seaborn scikit-learn\n# ! pip install torch torchvision torchaudio\n\nimport torch\nimport os\n\nos.environ[\"TORCH\"] = torch.__version__\n\n# On Colab we can have TORCH+CUDA on os.environ[\"TORCH\"]\n\n# Check if there is the cuda version on TORCH\nif torch.cuda.is_available():\n    print(\"CUDA is available\")\n    print(torch.version.cuda)\n    if \"+\" not in os.environ[\"TORCH\"]:\n        os.environ[\"TORCH\"] += \"+cu\" + \\\n            torch.version.cuda.replace(\".\", \"\")\n\nprint(os.environ[\"TORCH\"])\n","metadata":{"id":"-MnRckgeKz3Y","outputId":"e0d90604-8666-450f-9b2f-aef031568d35","execution":{"iopub.status.busy":"2023-12-01T07:11:24.034289Z","iopub.execute_input":"2023-12-01T07:11:24.034818Z","iopub.status.idle":"2023-12-01T07:11:27.483391Z","shell.execute_reply.started":"2023-12-01T07:11:24.034769Z","shell.execute_reply":"2023-12-01T07:11:27.482059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install pytorch geometric here beacause it depends on the torch version,\n# so we need to install it after the torch version is set, we can put it on\n# the requirements.txt\n! pip install torch_geometric\n\n# Optional dependencies:\n! pip install pyg_lib torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n\n# Graph\n# ! pip install igraph\n# ! pip install cdlib\n# ! pip install karateclub\n","metadata":{"id":"zcwu62n9Kz3Z","outputId":"2bf30d60-8b5c-461e-efa2-832fc97a9597","scrolled":true,"execution":{"iopub.status.busy":"2023-12-01T07:11:27.485215Z","iopub.execute_input":"2023-12-01T07:11:27.485736Z","iopub.status.idle":"2023-12-01T07:12:03.414922Z","shell.execute_reply.started":"2023-12-01T07:11:27.485701Z","shell.execute_reply":"2023-12-01T07:12:03.412685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Libraries","metadata":{"id":"z5ImUEyx4qNx"}},{"cell_type":"code","source":"# Import torch and os another time to reset the colab enviroment after PyG installation\nfrom IPython.display import FileLink, display\nimport subprocess\nimport torch\nimport os\nimport gc\n\n# Typing\nfrom typing import List, Tuple, Dict, Union, Callable, Optional, Iterable\nfrom collections import Counter, namedtuple\n\n# Deep Learning\nfrom torch_geometric.utils import from_networkx\nfrom torch_geometric.data import Data\nfrom torch_geometric.data import Batch\nfrom torch_geometric.nn import GCNConv, GATConv\nfrom torch_geometric.nn import global_mean_pool\nfrom torch.distributions import MultivariateNormal\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport scipy\nfrom scipy.stats import entropy\n\n# Graph\nfrom karateclub import GL2Vec, Graph2Vec, Node2Vec\nfrom cdlib import algorithms, evaluation\nimport cdlib\nimport networkx as nx\nimport igraph as ig\n\n# cuGraph\n# import cugraph as cnx\n\n\n# Misc\nfrom statistics import mean\nfrom enum import Enum\nfrom tqdm import trange\nfrom itertools import product\nimport math\nimport random\nimport json\nimport time\nimport copy\n\n\n# Plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"default\")","metadata":{"id":"39avPlWH4qNx","execution":{"iopub.status.busy":"2023-12-01T07:17:31.670612Z","iopub.execute_input":"2023-12-01T07:17:31.671064Z","iopub.status.idle":"2023-12-01T07:17:31.686431Z","shell.execute_reply.started":"2023-12-01T07:17:31.671032Z","shell.execute_reply":"2023-12-01T07:17:31.685282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{"id":"5VGevrvC4qNy"}},{"cell_type":"code","source":"# Only for the notebook\nTRAIN = False\n# Set to True to test the results with the baselines algorithms\nTEST = True","metadata":{"id":"dQJ3J16i-dkj","execution":{"iopub.status.busy":"2023-12-01T07:17:31.688301Z","iopub.execute_input":"2023-12-01T07:17:31.688874Z","iopub.status.idle":"2023-12-01T07:17:31.702886Z","shell.execute_reply.started":"2023-12-01T07:17:31.688840Z","shell.execute_reply":"2023-12-01T07:17:31.701543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass FilePaths(Enum):\n    \"\"\"Class to store file paths for data and models\"\"\"\n    # ° Local\n    # DATASETS_DIR = 'data'\n    # LOG_DIR    = 'logs/'\n    # TEST_DIR = 'test/'\n    # ° KAGGLE\n    DATASETS_DIR = '/kaggle/input/network-community'\n    LOG_DIR = '/kaggle/working/logs/'\n    TEST_DIR = '/kaggle/working/test/'\n\n    # TRAINED_MODEL = \"models/steps-10000_words-gre_eps-0_model.pth\"\n    TRAINED_MODEL = \"/kaggle/input/test-community-deception-model/steps-10000_words-gre_eps-0_.pth\"\n\n    # DATASETS\n    AMZ = DATASETS_DIR + \"/amz.gml\"\n    ASTR = DATASETS_DIR + \"/astr.gml\"\n    FB_75 = DATASETS_DIR + \"/fb-75.gml\"\n    POW = DATASETS_DIR + \"/pow.gml\"\n    NETS = DATASETS_DIR + \"/nets.gml\"\n    VOTE = DATASETS_DIR + \"/vote.gml\"\n    WORDS = DATASETS_DIR + \"/words.mtx\"\n    KAR = DATASETS_DIR + \"/kar.gml\"\n\n\nclass DetectionAlgorithmsNames(Enum):\n    \"\"\"\n    Enum class for the detection algorithms\n    \"\"\"\n    LOUV = \"louvain\"\n    WALK = \"walktrap\"\n    GRE = \"greedy\"\n    INF = \"infomap\"\n    LAB = \"label_propagation\"\n    EIG = \"eigenvector\"\n    BTW = \"edge_betweenness\"\n    SPIN = \"spinglass\"\n    OPT = \"optimal\"\n    SCD = \"scalable_community_detection\"\n\n\nclass SimilarityFunctionsNames(Enum):\n    \"\"\"\n    Enum class for the similarity functions\n    \"\"\"\n    # Community similarity functions\n    JAC = \"jaccard\"\n    OVE = \"overlap\"\n    SOR = \"sorensen\"\n    # Graph similarity functions\n    GED = \"ged\"  # Graph edit distance\n    JAC_1 = \"jaccard_1\"\n    JAC_2 = \"jaccard_2\"\n\n\n\nclass HyperParams(Enum):\n    \"\"\"Hyperparameters for the Environment\"\"\"\n\n    # ! REAL GRAPH Graph path (change the following line to change the graph)\n    GRAPH_NAME = FilePaths.ASTR.value\n    # ! Define the detection algorithm to use (change the following line to change the algorithm)\n    DETECTION_ALG_NAME = DetectionAlgorithmsNames.GRE.value\n    # Multiplier for the rewiring action number, i.e. (mean_degree * BETA)\n    BETA = 1\n    # ! Strength of the deception constraint, value between 0 (hard) and 1 (soft)\n    TAU = 0.5\n    # ° Hyperparameters  Testing ° #\n    # ! Weight to balance the penalty in the reward\n    # The higher its value the more importance the penalty will have\n    LAMBDA = [0.1]  # [0.01, 0.1, 1]\n    # ! Weight to balance the two metrics in the definition of the penalty\n    # The higher its value the more importance the distance between communities\n    # will have, compared with the distance between graphs\n    ALPHA = [0.7]  # [0.3, 0.5, 0.7]\n    # Multiplier for the number of maximum steps allowed\n    MAX_STEPS_MUL = 1\n\n    # Method to change the target community\n    # - 1: choose a random community\n    # - 2: choose the community with the length closest to the half of the maximum\n    #       length of the communities.\n    # - 3: choose a community based on the distribution of the number of\n    #       nodes in the communities\n    COMMUNITY_CHANGE_METHOD = 2\n\n    PREFERRED_COMMUNITY_SIZE = [0.5] # [0.2, 0.5, 0.8]\n\n    \"\"\" Graph Encoder Parameters \"\"\" \"\"\n    RANDOM_NODE2VEC = True  # If True, use Random features instead of Node2Vec\n    EMBEDDING_DIM = 128  # 256\n    WALK_NUMBER = 5  # 5, 10\n    WALK_LENGTH = 40  # 40, 80\n\n    \"\"\" Agent Parameters\"\"\"\n    # Chaneg target community and target node with a probability of EPSILON\n    EPSILON = [0]  # Between 0 and 100\n    # Networl Architecture\n    HIDDEN_SIZE_1 = 64\n    HIDDEN_SIZE_2 = 64\n    # Rehularization parameters\n    DROPOUT = 0.2\n    WEIGHT_DECAY = 1e-3\n    # Hyperparameters for the ActorCritic\n    EPS_CLIP = np.finfo(np.float32).eps.item()  # 0.2\n    BEST_REWARD = -np.inf\n    # ° Hyperparameters  Testing ° #\n    # ! Learning rate, it controls how fast the network learns\n    LR = [7e-4]  # [1e-7, 1e-4, 1e-1]\n    # ! Discount factor:\n    # - 0: only the reward on the next step is important\n    # - 1: a reward in the future is as important as a reward on the next step\n    GAMMA = [0.95]  # [0.9, 0.95]\n\n    \"\"\" Training Parameters \"\"\"\n    # Number of episodes to collect experience\n    MAX_EPISODES = 10000\n    # Dictonary for logging\n    LOG_DICT = {\n        # List of rewards per episode\n        \"train_reward_list\": [],\n        # Avg reward per episode, with the last value multiplied per 10 if the\n        # goal is reached\n        \"train_reward_mul\": [],\n        # Total reward per episode\n        \"train_reward\": [],\n        # Number of steps per episode\n        \"train_steps\": [],\n        # Average reward per episode\n        \"train_avg_reward\": [],\n        # Average Actor loss per episode\n        \"a_loss\": [],\n        # Average Critic loss per episode\n        \"v_loss\": [],\n        # set max number of training episodes\n        \"train_episodes\": MAX_EPISODES,\n    }\n\n    \"\"\"Evaluation Parameters\"\"\"\n    # ! Change the following parameters according to the hyperparameters to test\n    STEPS_EVAL = 100\n    LR_EVAL = 0.0001  # LR[0]\n    GAMMA_EVAL = 0.7  # GAMMA[0]\n    LAMBDA_EVAL = 0.1  # LAMBDA[0]\n    ALPHA_EVAL = 0.7  # ALPHA[0]\n    EPSILON_EVAL = 25  # EPSILON[0]\n\n    \"\"\"Graph Generation Parameters\"\"\"\n    # ! Change the following parameters to modify the graph\n    # Number of nodes\n    N_NODE = 150\n    # Power law exponent for the degree distribution of the created graph.\n    TAU1 = 2\n    # Power law exponent for the community size distribution in the created graph.\n    TAU2 = 1.1\n    # Fraction of inter-community edges incident to each node.\n    MU = 0.1\n\n    # Desired average degree of nodes in the created graph.\n    AVERAGE_DEGREE = int(0.035 * N_NODE)  # 20\n    # Minimum degree of nodes in the created graph\n    MIN_DEGREE = None  # 30\n    # Maximum degree of nodes in the created graph\n    MAX_DEGREE = int(0.1 * N_NODE)\n\n    # Minimum size of communities in the graph.\n    MIN_COMMUNITY = int(0.05 * N_NODE)\n    # Maximum size of communities in the graph.\n    MAX_COMMUNITY = int(0.2 * N_NODE)\n\n    # Maximum number of iterations to try to create the community sizes, degree distribution, and community affiliations.\n    MAX_ITERS = 5000\n    # Seed for the random number generator.\n    SEED = 10","metadata":{"id":"Pairxi9g4qNy","execution":{"iopub.status.busy":"2023-12-01T07:17:31.710519Z","iopub.execute_input":"2023-12-01T07:17:31.711349Z","iopub.status.idle":"2023-12-01T07:17:31.737021Z","shell.execute_reply.started":"2023-12-01T07:17:31.711310Z","shell.execute_reply":"2023-12-01T07:17:31.735423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utils Functions","metadata":{"id":"OOnPtOIMKz3b"}},{"cell_type":"code","source":"class Utils:\n  \"\"\"Class to store utility functions\"\"\"\n\n  @staticmethod\n  def import_mtx_graph(file_path: str) -> nx.Graph:\n      \"\"\"\n      Import a graph from a .mtx file\n\n      Parameters\n      ----------\n      file_path : str\n          File path of the .mtx file\n\n      Returns\n      -------\n      nx.Graph\n          Graph imported from the .mtx file\n      \"\"\"\n      # try:\n      # Check if the graph file is in the .mtx format or .gml\n      if file_path.endswith(\".txt\"):\n          # if is the POW graph use weighted edges\n          if file_path.endswith(\"pow.txt\"):\n              graph = nx.read_weighted_edgelist(file_path, nodetype=int)\n          else:\n              graph = nx.read_edgelist(file_path, nodetype=int)\n      elif file_path.endswith(\".mtx\"):\n          graph_matrix = scipy.io.mmread(file_path)\n          graph = nx.Graph(graph_matrix)\n      elif file_path.endswith(\".gml\"):\n          graph = nx.read_gml(file_path, label=\"id\")\n      else:\n          raise ValueError(\"File format not supported\")\n\n      for node in graph.nodes:\n          # graph.nodes[node]['name'] = node\n          graph.nodes[node][\"num_neighbors\"] = len(list(graph.neighbors(node)))\n      return graph\n      # except Exception as exception:\n      #     print(\"Error: \", exception)\n      #     return None\n\n  @staticmethod\n  def generate_lfr_benchmark_graph(\n      n: int = HyperParams.N_NODE.value,\n      tau1: float = HyperParams.TAU1.value,\n      tau2: float = HyperParams.TAU2.value,\n      mu: float = HyperParams.MU.value,\n      average_degree: int = HyperParams.AVERAGE_DEGREE.value,\n      min_degree: int = HyperParams.MIN_DEGREE.value,\n      max_degree: int = HyperParams.MAX_DEGREE.value,\n      min_community: int = HyperParams.MIN_COMMUNITY.value,\n      max_community: int = HyperParams.MAX_COMMUNITY.value,\n      max_iters: int = HyperParams.MAX_ITERS.value,\n      seed: int = HyperParams.SEED.value,\n  ) -> Tuple[nx.Graph, str]:\n      \"\"\"\n      Generate a LFR benchmark graph for community detection algorithms.\n\n      Parameters\n      ----------\n      n : int, optional\n          Number of nodes, by default 500\n      tau1 : float, optional\n          _description_, by default 3\n      tau2 : float, optional\n          _description_\n      mu : float, optional\n          Mixing parameter, by default 0.1\n      average_degree : int, optional\n          Average degree of the nodes, by default 20\n      min_degree : int, optional\n          Minimum degree of the nodes, by default 20\n      max_degree : int, optional\n          Maximum degree of the nodes, by default 50\n      min_community : int, optional\n          Minimum number of communities, by default 10\n      max_community : int, optional\n          Maximum number of communities, by default 50\n      max_iters : int, optional\n          Maximum number of iterations, by default 5000\n      seed : int, optional\n          Seed for the random number generator, by default 10\n\n      Returns\n      -------\n      nx.Graph\n          Synthetic graph generated with the LFR benchmark\n      file_path : str\n          Path to the file where the graph is saved\n      \"\"\"\n      graph = nx.generators.community.LFR_benchmark_graph(\n          n=n,\n          tau1=tau1,\n          tau2=tau2,\n          mu=mu,\n          average_degree=average_degree,\n          min_degree=min_degree,\n          max_degree=max_degree,\n          min_community=min_community,\n          max_community=max_community,\n          max_iters=max_iters,\n          seed=seed,\n      )\n      # Save the graph in a .mtx file\n      file_path = FilePaths.DATASETS_DIR.value + f\"/lfr_benchmark_node-{n}\"\n      # ! FOR KAGGLE NOTEBOOK\n      # file_path = f\"/kaggle/working/lfr_benchmark_node-{n}.mtx\"\n      # Write .gml file\n      # nx.write_gml(graph, f\"{file_path}.gml\")\n      # Write .mtx file\n      nx.write_edgelist(graph, f\"{file_path}.mtx\", data=False)\n\n      # Delete community attribute from the nodes to handle PyG compatibility\n      for node in graph.nodes:\n          if \"community\" in graph.nodes[node]:\n              del graph.nodes[node][\"community\"]\n      for edge in graph.edges:\n          graph.edges[edge][\"weight\"] = 1\n      return graph, file_path\n\n  @staticmethod\n  def check_dir(path: str):\n      \"\"\"\n      Check if the directory exists, if not create it.\n\n      Parameters\n      ----------\n      path : str\n          Path to the directory\n      \"\"\"\n      if not os.path.exists(path):\n          os.makedirs(path)\n\n  @staticmethod\n  def plot_training(\n      log: dict,\n      env_name: str,\n      detection_algorithm: str,\n      file_path: str,\n      window_size: int = int(HyperParams.MAX_EPISODES.value / 100),\n  ):\n      \"\"\"Plot the training results\n\n      Parameters\n      ----------\n      log : dict\n          Dictionary containing the training logs\n      env_name : str\n          Name of the environment\n      detection_algorithm : str\n          Name of the detection algorithm\n      file_path : str\n          Path to save the plot\n      window_size : int, optional\n          Size of the rolling window, by default 100\n      \"\"\"\n\n      def plot_seaborn(\n          df: pd.DataFrame,\n          path: str,\n          env_name: str,\n          detection_algorithm: str,\n          labels: Tuple[str, str],\n          colors: Tuple[str, str],\n      ) -> None:\n          sns.set_style(\"darkgrid\")\n          sns.lineplot(data=df, x=\"Episode\", y=labels[0], color=colors[0])\n          sns.lineplot(\n              data=df,\n              x=\"Episode\",\n              y=labels[1],\n              color=colors[1],\n              estimator=\"mean\",\n              errorbar=None,\n          )\n          plt.title(\n              f\"Training on {env_name} graph with {detection_algorithm} algorithm\"\n          )\n          plt.xlabel(\"Episode\")\n          plt.ylabel(labels[0])\n          plt.savefig(path)\n          plt.clf()\n\n      if window_size < 1:\n          window_size = 1\n      df = pd.DataFrame(\n          {\n              \"Episode\": range(len(log[\"train_avg_reward\"])),\n              \"Avg Reward\": log[\"train_avg_reward\"],\n              \"Steps per Epoch\": log[\"train_steps\"],\n              \"Goal Reward\": log[\"train_reward_mul\"],\n              \"Goal Reached\": [\n                  1 / log[\"train_steps\"][i]\n                  if log[\"train_reward_list\"][i][-1] > 1\n                  else 0\n                  for i in range(len(log[\"train_steps\"]))\n              ],\n          }\n      )\n      df[\"Rolling_Avg_Reward\"] = df[\"Avg Reward\"].rolling(window_size).mean()\n      df[\"Rolling_Steps\"] = df[\"Steps per Epoch\"].rolling(window_size).mean()\n      df[\"Rolling_Goal_Reward\"] = df[\"Goal Reward\"].rolling(window_size).mean()\n      df[\"Rolling_Goal_Reached\"] = df[\"Goal Reached\"].rolling(window_size).mean()\n      plot_seaborn(\n          df,\n          file_path + \"/training_reward.png\",\n          env_name,\n          detection_algorithm,\n          (\"Avg Reward\", \"Rolling_Avg_Reward\"),\n          (\"lightsteelblue\", \"darkblue\"),\n      )\n      plot_seaborn(\n          df,\n          file_path + \"/training_steps.png\",\n          env_name,\n          detection_algorithm,\n          (\"Steps per Epoch\", \"Rolling_Steps\"),\n          (\"thistle\", \"purple\"),\n      )\n      plot_seaborn(\n          df,\n          file_path + \"/training_goal_reward.png\",\n          env_name,\n          detection_algorithm,\n          (\"Goal Reward\", \"Rolling_Goal_Reward\"),\n          (\"darkgray\", \"black\"),\n      )\n      plot_seaborn(\n          df,\n          file_path + \"/training_goal_reached.png\",\n          env_name,\n          detection_algorithm,\n          (\"Goal Reached\", \"Rolling_Goal_Reached\"),\n          (\"darkgray\", \"black\"),\n      )\n\n      df = pd.DataFrame(\n          {\n              \"Episode\": range(len(log[\"a_loss\"])),\n              \"Actor Loss\": log[\"a_loss\"],\n              \"Critic Loss\": log[\"v_loss\"],\n          }\n      )\n      df[\"Rolling_Actor_Loss\"] = df[\"Actor Loss\"].rolling(window_size).mean()\n      df[\"Rolling_Critic_Loss\"] = df[\"Critic Loss\"].rolling(window_size).mean()\n      plot_seaborn(\n          df,\n          file_path + \"/training_a_loss.png\",\n          env_name,\n          detection_algorithm,\n          (\"Actor Loss\", \"Rolling_Actor_Loss\"),\n          (\"palegreen\", \"darkgreen\"),\n      )\n      plot_seaborn(\n          df,\n          file_path + \"/training_v_loss.png\",\n          env_name,\n          detection_algorithm,\n          (\"Critic Loss\", \"Rolling_Critic_Loss\"),\n          (\"lightcoral\", \"darkred\"),\n      )\n\n  ############################################################################\n  #                               EVALUATION                                 #\n  ############################################################################\n  @staticmethod\n  def save_test(\n      log: dict, files_path: str, log_name: str, algs: List[str], metrics: List[str]\n  ):\n      \"\"\"Save and Plot the testing results\n\n      Parameters\n      ----------\n      log : dict\n          Dictionary containing the training logs\n      files_path : str\n          Path to save the plot\n      log_name : str\n          Name of the log file\n      algs : List[str]\n          List of algorithms names to evaluate\n      metrics : List[str]\n          List of metrics to evaluate\n      \"\"\"\n      file_name = f\"{files_path}/{log_name}.json\"\n      # Save json file\n      with open(file_name, \"w\", encoding=\"utf-8\") as f:\n          json.dump(log, f, indent=4)\n\n      for metric in metrics:\n          # Create a DataFrame with the mean values of each algorithm for the metric\n          df = pd.DataFrame(\n              {\n                  \"Algorithm\": algs,\n                  metric.capitalize(): [mean(log[alg][metric]) for alg in algs],\n              }\n          )\n\n          # Convert the goal column to percentage\n          if metric == \"goal\":\n              df[metric.capitalize()] = df[metric.capitalize()] * 100\n\n          sns.barplot(\n              data=df,\n              x=\"Algorithm\",\n              y=metric.capitalize(),\n              palette=sns.color_palette(\"Set1\"),\n          )\n          plt.title(\n              f\"Evaluation on {log['env']['dataset']} graph with {log['env']['detection_alg']} algorithm\"\n          )\n          plt.xlabel(\"Algorithm\")\n          if metric == \"goal\":\n              plt.ylabel(f\"{metric.capitalize()} reached %\")\n          elif metric == \"time\":\n              plt.ylabel(f\"{metric.capitalize()} (s)\")\n          else:\n              plt.ylabel(metric.capitalize())\n          plt.savefig(f\"{files_path}/{log_name}_{metric}.png\")\n          plt.clf()","metadata":{"id":"lufJQbjyKz3b","execution":{"iopub.status.busy":"2023-12-01T07:17:31.767463Z","iopub.execute_input":"2023-12-01T07:17:31.767995Z","iopub.status.idle":"2023-12-01T07:17:31.816661Z","shell.execute_reply.started":"2023-12-01T07:17:31.767943Z","shell.execute_reply":"2023-12-01T07:17:31.814798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Community Algorithms","metadata":{"id":"iJUWAWt24qNz"}},{"cell_type":"markdown","source":"### Community Detection","metadata":{"id":"nwTTb1F-HsRC"}},{"cell_type":"code","source":"'''\nclass CommunityDetectionAlgorithm(object):\n    \"\"\"Class for the community detection algorithms using CDLIB\"\"\"\n    def __init__(self, alg_name: str) -> None:\n        \"\"\"\n        Initialize the DetectionAlgorithm object\n\n        Parameters\n        ----------\n        alg_name : str\n            The name of the algorithm\n        \"\"\"\n        self.alg_name = alg_name\n\n    def compute_community(self, graph: nx.Graph) -> cdlib.NodeClustering:\n        \"\"\"Compute the community partition of the graph\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            Input graph\n\n        Returns\n        -------\n        cdlib.NodeClustering\n            Cdlib NodeClustering object\n        \"\"\"\n        # Rename DetectionAlgorithms Enum to da for convenience\n        da = DetectionAlgorithmsNames\n        # Choose the algorithm\n        if self.alg_name == da.LOUV.value:\n            return algorithms.louvain(graph)\n        elif self.alg_name == da.WALK.value:\n            return algorithms.walktrap(graph)\n        elif self.alg_name == da.GRE.value:\n            return algorithms.greedy_modularity(graph)\n        elif self.alg_name == da.INF.value:\n            return algorithms.infomap(graph)\n        elif self.alg_name == da.LAB.value:\n            # ! Return a EdgeClustering object\n            return algorithms.label_propagation(graph)\n        elif self.alg_name == da.EIG.value:\n            return algorithms.eigenvector(graph)\n        # elif self.alg_name == da.BTW.value:\n        #     return self.compute_btw(graph, args)\n        elif self.alg_name == da.SPIN.value:\n            return algorithms.spinglass(graph)\n        # elif self.alg_name == da.OPT.value:\n        #    return self.compute_opt(graph, args)\n        # elif self.alg_name == da.SCD.value:\n        #    return self.compute_scd(graph)\n        else:\n            raise ValueError('Invalid algorithm name')\n'''\n\n\nclass CommunityDetectionAlgorithm(object):\n    \"\"\"Class for the community detection algorithms using iGraph\"\"\"\n\n    def __init__(self, alg_name: str) -> None:\n        \"\"\"\n        Initialize the DetectionAlgorithm object\n\n        Parameters\n        ----------\n        alg_name : str\n            The name of the algorithm\n        \"\"\"\n        self.alg_name = alg_name\n        self.ig_graph = None\n\n    def networkx_to_igraph(self, graph: nx.Graph) -> ig.Graph:\n        \"\"\"\n        Convert NetworkX graph to iGraph graph, in this way we can use\n        iGraph's community detection algorithms\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            The graph to be converted\n\n        Returns\n        ----------\n        ig.Graph\n            The converted graph\n        \"\"\"\n        self.ig_graph = ig.Graph.from_networkx(graph)\n        return self.ig_graph\n\n    def compute_community(self, graph: nx.Graph, args: dict = None) -> List[List[int]]:\n        \"\"\"\n        Compute the community detection algorithm\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            The graph to be computed\n        args : dict\n            The arguments for the algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        # Transform the graph to igraph\n        graph = self.networkx_to_igraph(graph)\n\n        # Rename DetectionAlgorithms Enum to da for convenience\n        da = DetectionAlgorithmsNames\n        # Choose the algorithm\n        if self.alg_name == da.LOUV.value:\n            return self.compute_louv(graph, args)\n        elif self.alg_name == da.WALK.value:\n            return self.compute_walk(graph, args)\n        elif self.alg_name == da.GRE.value:\n            return self.compute_gre(graph, args)\n        elif self.alg_name == da.INF.value:\n            return self.compute_inf(graph, args)\n        elif self.alg_name == da.LAB.value:\n            return self.compute_lab(graph, args)\n        elif self.alg_name == da.EIG.value:\n            return self.compute_eig(graph, args)\n        elif self.alg_name == da.BTW.value:\n            return self.compute_btw(graph, args)\n        elif self.alg_name == da.SPIN.value:\n            return self.compute_spin(graph, args)\n        elif self.alg_name == da.OPT.value:\n            return self.compute_opt(graph, args)\n        elif self.alg_name == da.SCD.value:\n            return self.compute_scd(graph)\n        else:\n            raise ValueError('Invalid algorithm name')\n\n    def vertexcluster_to_list(self, cluster: ig.VertexClustering) -> cdlib.NodeClustering:\n        \"\"\"\n        Convert iGraph.VertexClustering object to list of list of vertices in each cluster\n\n        Parameters\n        ----------\n        cluster : ig.VertexClustering\n            cluster from iGraph community detection algorithm\n\n        Returns\n        -------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        com_list = [c for c in cluster]\n        # Create a NodeClustering object\n        node_cluster = cdlib.NodeClustering(com_list, self.ig_graph)\n        return node_cluster\n\n    def plot_graph(self) -> plt:\n        \"\"\"Plot the graph using iGraph\n\n        Returns\n        ---------\n        plot: plt\n            The plot of the graph\n\n        \"\"\"\n        # fig, ax = plt.subplots(figsize=(10, 10))\n        plot = ig.plot(\n            self.ig_graph,\n            mark_groups=True,\n            vertex_size=20,\n            edge_color='black',\n            vertex_label=[v.index for v in self.ig_graph.vs],\n            bbox=(0, 0, 500, 500),\n            # target=ax,\n        )\n        return plot\n\n    def compute_louv(self, graph: ig.Graph, args_louv: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Louvain community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_louv : dict\n            The arguments for the Louvain algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_louv is None:\n            louv = graph.community_multilevel()\n        else:\n            louv = graph.community_multilevel(**args_louv)\n        return self.vertexcluster_to_list(louv)\n\n    def compute_walk(self, graph: ig.Graph, args_walk: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Walktrap community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_walk : dict\n            The arguments for the Walktrap algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_walk is None:\n            walk = graph.community_walktrap()\n        else:\n            walk = graph.community_walktrap(**args_walk)\n        # Need to be converted to VertexClustering object\n        return self.vertexcluster_to_list(walk.as_clustering())\n\n    def compute_gre(self, graph: ig.Graph, args_gre: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Greedy community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_greed : dict\n            The arguments for the Greedy algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_gre is None:\n            greed = graph.community_fastgreedy()\n        else:\n            greed = graph.community_fastgreedy(**args_gre)\n        # Need to be converted to VertexClustering object\n        return self.vertexcluster_to_list(greed.as_clustering())\n\n    def compute_inf(self, graph: ig.Graph, args_infomap: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Infomap community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_infomap : dict\n            The arguments for the Infomap algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_infomap is None:\n            infomap = graph.community_infomap()\n        else:\n            infomap = graph.community_infomap(**args_infomap)\n        return self.vertexcluster_to_list(infomap)\n\n    def compute_lab(self, graph: ig.Graph, args_lab: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Label Propagation community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_lab : dict\n            The arguments for the Label Propagation algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_lab is None:\n            lab = graph.community_label_propagation()\n        else:\n            lab = graph.community_label_propagation(**args_lab)\n        return self.vertexcluster_to_list(lab)\n\n    def compute_eig(self, graph: ig.Graph, args_eig: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Eigenvector community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_eig : dict\n            The arguments for the Eigenvector algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_eig is None:\n            eig = graph.community_leading_eigenvector()\n        else:\n            eig = graph.community_leading_eigenvector(**args_eig)\n        return self.vertexcluster_to_list(eig)\n\n    def compute_btw(self, graph: ig.Graph, args_btw: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Edge Betweenness community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_btw : dict\n            The arguments for the Betweenness algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if btw is None:\n            btw = graph.community_edge_betweenness()\n        else:\n            btw = graph.community_edge_betweenness(**args_btw)\n        # Need to be converted to VertexClustering object\n        return self.vertexcluster_to_list(btw.as_clustering())\n\n    def compute_spin(self, graph: ig.Graph, args_spin: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Spin Glass community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_spin : dict\n            The arguments for the Spin Glass algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_spin is None:\n            spin = graph.community_spinglass()\n        else:\n            spin = graph.community_spinglass(**args_spin)\n        return self.vertexcluster_to_list(spin)\n\n    def compute_opt(self, graph: ig.Graph, args_opt: dict) -> List[List[int]]:\n        \"\"\"\n        Compute the Optimal community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n        args_opt : dict\n            The arguments for the Optimal algorithm\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        if args_opt is None:\n            opt = graph.community_optimal_modularity()\n        else:\n            opt = graph.community_optimal_modularity(**args_opt)\n        return self.vertexcluster_to_list(opt)\n\n    def compute_scd(self, graph: ig.Graph) -> List[List[int]]:\n        \"\"\"\n        Compute the Surprise community detection algorithm\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            The graph to be clustered\n\n        Returns\n        ----------\n        List[List[int]]\n            list of list of vertices in each cluster\n        \"\"\"\n        # Write the graph to a text file\n        self.write_graph_to_file(graph, \"output.txt\")\n        # Execute SCD algorithm from the git submodule\n        os.system(\"./../src/SCD/build/scd -f output.txt\")\n        result_list = self.read_data_from_file('communities.dat')\n        return result_list\n\n    @staticmethod\n    def write_graph_to_file(graph: ig.Graph, file_path: str) -> None:\n        \"\"\"\n        Write the graph to a text file, where each line is an\n        edge in the graph.\n\n        Parameters\n        ----------\n        graph : ig.Graph\n            Graph object to write to file\n        file_path : str\n            file path of the output file\n        \"\"\"\n        with open(file_path, 'w', encoding='utf-8') as file:\n            for edge in graph.get_edgelist():\n                # To ensure we don't duplicate edges (x, y) and (y, x)\n                if edge[0] < edge[1]:\n                    file.write(f\"{edge[0]} {edge[1]}\\n\")\n\n    @staticmethod\n    def read_data_from_file(file_path: str) -> List[List[int]]:\n        \"\"\"\n        Read data from file and return a list of lists, where each row list of\n        nodes is a community.\n\n        Parameters\n        ----------\n        file_path : str\n            File path to the data file.\n\n        Returns\n        -------\n        List[List[int]]\n            List of lists, where each row list of nodes is a community.\n        \"\"\"\n        data_list = []\n        with open(file_path, 'r', encoding='utf-8') as file:\n            for line in file:\n                numbers = [int(num) for num in line.strip().split()]\n                data_list.append(numbers)\n        return data_list\n","metadata":{"id":"Abzm0lJQKz3d","execution":{"iopub.status.busy":"2023-12-01T07:17:31.840483Z","iopub.execute_input":"2023-12-01T07:17:31.841027Z","iopub.status.idle":"2023-12-01T07:17:31.887545Z","shell.execute_reply.started":"2023-12-01T07:17:31.840988Z","shell.execute_reply":"2023-12-01T07:17:31.886208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Node Hiding","metadata":{"id":"pee_D4QvHvII"}},{"cell_type":"markdown","source":"#### Random Hiding","metadata":{"id":"wlGbeHzwH0rJ"}},{"cell_type":"code","source":"class RandomHiding():\n    \n    def __init__(\n        self, \n        env, \n        steps: int, \n        target_community: List[int]):\n        self.env = env\n        self.graph = self.env.original_graph\n        self.steps = steps\n        self.target_node = self.env.node_target\n        self.target_community = target_community\n        self.detection_alg = self.env.detection\n        self.original_community_structure = copy.deepcopy(self.env.original_community_structure)\n        self.possible_edges = self.get_possible_action() \n        \n    def get_possible_action(self):\n        # Put all edge between the target node and its neighbors in a list\n        possible_actions_remove = []\n        for neighbor in self.graph.neighbors(self.target_node):\n            possible_actions_remove.append((self.target_node, neighbor))\n        \n        # Put all the edges that aren't neighbors of the target node in a list\n        possible_actions_add = []\n        for node in self.graph.nodes():\n            if node != self.target_node and node not in self.graph.neighbors(self.target_node):\n                possible_actions_add.append((self.target_node, node))\n        possible_actions = possible_actions_add + possible_actions_remove\n\n        return possible_actions\n    \n    def hide_target_node_from_community(self) -> Tuple[nx.Graph, List[int], int]:\n        \"\"\"\n        Hide the target node from the target community by rewiring its edges, \n        choosing randomly between adding or removing an edge.\n        \n        Returns\n        -------\n        Tuple[nx.Graph, List[int], int]\n            The new graph, the new community structure and the number of steps\n        \"\"\"\n        graph = self.graph.copy()\n        possible_edges = copy.copy(self.possible_edges)\n        communities = self.original_community_structure\n        done = False\n        steps = self.steps\n        random.seed(time.time())\n        # TEST\n        while steps > 0: # and not done:           \n            \n            # index = random.randint(0, len(possible_edges)-1)\n            # edge = possible_edges.pop(index)\n            edge = random.choice(possible_edges)\n            possible_edges.remove(edge)\n            \n            \n            if graph.has_edge(*edge):\n                graph.remove_edge(*edge)\n            elif graph.has_edge(*edge[::-1]):\n                graph.remove_edge(*edge[::-1])\n            else:\n                graph.add_edge(*edge)\n            \n            # TEST, do not compute the new community structure at each step\n            # # Compute the new community structure\n            # communities = self.detection_alg.compute_community(graph)\n            # new_community = self.get_new_community(communities)\n\n            # check = self.check_goal(new_community)\n            # if check == 1:\n            #     # If the target community is a subset of the new community, the episode is finished\n            #     done = True\n            steps -= 1\n        # TEST, compute the new community structure only at the end of the episode\n        # Compute the new community structure\n        communities = self.detection_alg.compute_community(graph)\n        step = self.steps - steps\n        return graph, communities, step\n\n    def get_new_community(\n                self,\n                new_community_structure: List[List[int]]) -> List[int]:\n        \"\"\"\n        Search the community target in the new community structure after \n        deception. As new community target after the action, we consider the \n        community that contains the target node, if this community satisfies \n        the deception constraint, the episode is finished, otherwise not.\n\n        Parameters\n        ----------\n        node_target : int\n            Target node to be hidden from the community\n        new_community_structure : List[List[int]]\n            New community structure after deception\n\n        Returns\n        -------\n        List[int]\n            New community target after deception\n        \"\"\"\n        # if new_community_structure is None:\n        #     # The agent did not perform any rewiring, i.e. are the same communities\n        #     return self.target_community\n        for community in new_community_structure.communities:\n            if self.target_node in community:\n                return community\n        raise ValueError(\"Community not found\")\n\n    def check_goal(self, new_community: int) -> int:\n        \"\"\"\n        Check if the goal of hiding the target node was achieved\n\n        Parameters\n        ----------\n        new_community : int\n            New community of the target node\n\n        Returns\n        -------\n        int\n            1 if the goal was achieved, 0 otherwise\n        \"\"\"\n        if len(new_community) == 1:\n            return 1\n        # Copy the communities to avoid modifying the original ones\n        new_community_copy = new_community.copy()\n        new_community_copy.remove(self.target_node)\n        old_community_copy = self.target_community.copy()\n        old_community_copy.remove(self.target_node)\n        # Compute the similarity between the new and the old community\n        similarity = self.env.community_similarity(\n            new_community_copy,\n            old_community_copy\n        )\n        del new_community_copy, old_community_copy\n        if similarity <= self.env.tau:\n            return 1\n        return 0","metadata":{"id":"FzIcZjzQH27Q","execution":{"iopub.status.busy":"2023-12-01T07:17:31.890656Z","iopub.execute_input":"2023-12-01T07:17:31.891181Z","iopub.status.idle":"2023-12-01T07:17:31.918026Z","shell.execute_reply.started":"2023-12-01T07:17:31.891135Z","shell.execute_reply":"2023-12-01T07:17:31.916396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Degree Hiding","metadata":{"id":"4heBBDFWIKmR"}},{"cell_type":"code","source":"class DegreeHiding:\n    def __init__(self, env, steps: int, target_community: List[int]):\n        self.env = env\n        self.graph = self.env.original_graph\n        self.steps = steps\n        self.target_node = self.env.node_target\n        self.target_community = target_community\n        self.detection_alg = self.env.detection\n        self.original_community_structure = copy.deepcopy(\n            self.env.original_community_structure\n        )\n        self.possible_edges = self.get_possible_action()\n\n    def get_possible_action(self):\n        # Put all edge between the target node and its neighbors in a list\n        possible_actions_remove = []\n        for neighbor in self.graph.neighbors(self.target_node):\n            possible_actions_remove.append((self.target_node, neighbor))\n\n        # Put all the edges that aren't neighbors of the target node in a list\n        possible_actions_add = []\n        for node in self.graph.nodes():\n            if node != self.target_node and node not in self.graph.neighbors(\n                self.target_node\n            ):\n                possible_actions_add.append((self.target_node, node))\n        possible_action = possible_actions_add + possible_actions_remove\n        return possible_action\n\n    def hide_target_node_from_community(self) -> Tuple[nx.Graph, List[int], int]:\n        \"\"\"\n        Hide the target node from the target community by rewiring its edges,\n        choosing the node with the highest degree between adding or removing an edge.\n\n        Returns\n        -------\n        Tuple[nx.Graph, List[int], int]\n            The new graph, the new community structure and the number of steps\n        \"\"\"\n        graph = self.graph.copy()\n        communities = self.original_community_structure\n        done = False\n        steps = self.steps\n        # From the list possible_edges, create a list of tuples\n        # (node1, node2, degree_of_node2)\n        possible_edges = []\n        for edge in self.possible_edges:\n            possible_edges.append((edge[0], edge[1], graph.degree(edge[1])))\n        \n        # TEST\n        while steps > 0:  # and not done:\n            # Choose the edge with the highest degree\n            max_tuple = max(possible_edges, key=lambda x: x[2])\n            index = possible_edges.index(max_tuple)\n            edge = possible_edges.pop(index)\n            edge = (edge[0], edge[1])\n\n            if graph.has_edge(*edge):\n                graph.remove_edge(*edge)\n            elif graph.has_edge(*edge[::-1]):\n                graph.remove_edge(*edge[::-1])\n            else:\n                graph.add_edge(*edge)\n            # Update the degree of the node\n            possible_edges.append((edge[0], edge[1], graph.degree(edge[1])))\n\n            # TEST, do not compute the new community structure at each step\n            # # Compute the new community structure\n            # communities = self.detection_alg.compute_community(graph)\n            # new_community = self.get_new_community(communities)\n\n            # check = self.check_goal(new_community)\n            # if check == 1:\n            #     # If the target community is a subset of the new community, the episode is finished\n            #     done = True\n            steps -= 1\n        \n        # TEST, compute the new community structure only at the end\n        communities = self.detection_alg.compute_community(graph)\n        step = self.steps - steps\n        return graph, communities, step\n\n    def get_new_community(self, new_community_structure: List[List[int]]) -> List[int]:\n        \"\"\"\n        Search the community target in the new community structure after\n        deception. As new community target after the action, we consider the\n        community that contains the target node, if this community satisfies\n        the deception constraint, the episode is finished, otherwise not.\n\n        Parameters\n        ----------\n        node_target : int\n            Target node to be hidden from the community\n        new_community_structure : List[List[int]]\n            New community structure after deception\n\n        Returns\n        -------\n        List[int]\n            New community target after deception\n        \"\"\"\n        if new_community_structure is None:\n            # The agent did not perform any rewiring, i.e. are the same communities\n            return self.target_community\n        for community in new_community_structure.communities:\n            if self.target_node in community:\n                return community\n        raise ValueError(\"Community not found\")\n\n    def check_goal(self, new_community: int) -> int:\n        \"\"\"\n        Check if the goal of hiding the target node was achieved\n\n        Parameters\n        ----------\n        new_community : int\n            New community of the target node\n\n        Returns\n        -------\n        int\n            1 if the goal was achieved, 0 otherwise\n        \"\"\"\n        if len(new_community) == 1:\n            return 1\n        # Copy the communities to avoid modifying the original ones\n        new_community_copy = new_community.copy()\n        new_community_copy.remove(self.target_node)\n        old_community_copy = self.target_community.copy()\n        old_community_copy.remove(self.target_node)\n        # Compute the similarity between the new and the old community\n        similarity = self.env.community_similarity(\n            new_community_copy, old_community_copy\n        )\n        del new_community_copy, old_community_copy\n        if similarity <= self.env.tau:\n            return 1\n        return 0","metadata":{"id":"Gv5y7U2xHyrI","execution":{"iopub.status.busy":"2023-12-01T07:17:31.920646Z","iopub.execute_input":"2023-12-01T07:17:31.921034Z","iopub.status.idle":"2023-12-01T07:17:31.947426Z","shell.execute_reply.started":"2023-12-01T07:17:31.921004Z","shell.execute_reply":"2023-12-01T07:17:31.945861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Roam Hiding","metadata":{"id":"5yNPbm9gL8OI"}},{"cell_type":"code","source":"\n\nclass RoamHiding:\n    \"\"\"Given a network and a source node v,our objective is to conceal the\n    importance of v by decreasing its centrality without compromising its\n    influence over the network.\n\n    From the article \"Hiding Individuals and Communities in a Social Network\".\n    \"\"\"\n\n    def __init__(\n        self, graph: nx.Graph, target_node: int, edge_budget: int, detection_alg: str\n    ) -> None:\n        self.graph = graph\n        self.target_node = target_node\n        self.edge_budget = edge_budget\n        self.detection_alg = CommunityDetectionAlgorithm(detection_alg)\n\n    def roam_heuristic(self, budget: int) -> tuple:\n        \"\"\"\n        The ROAM heuristic given a budget b:\n            - Step 1: Remove the link between the source node, v, and its\n            neighbour of choice, v0;\n            - Step 2: Connect v0 to b − 1 nodes of choice, who are neighbours\n            of v but not of v0 (if there are fewer than b − 1 such neighbours,\n            connect v0 to all of them).\n\n        Returns\n        -------\n        graph : nx.Graph\n            The graph after the ROAM heuristic.\n        \"\"\"\n        graph = self.graph.copy()\n        budget = self.edge_budget\n        # ° --- Step 1 --- ° #\n        target_node_neighbours = list(graph.neighbors(self.target_node))\n        if len(target_node_neighbours) == 0:\n            print(\"No neighbours for the target node\", self.target_node)\n            return graph, self.detection_alg.compute_community(graph)\n\n        # Choose v0 as the neighbour of target_node with the most connections\n        v0 = target_node_neighbours[0]\n        for v in target_node_neighbours:\n            if graph.degree[v] > graph.degree[v0]:\n                v0 = v\n        # v0 = random.choice(target_node_neighbours)    # Random choice\n        # Remove the edge between v and v0\n        graph.remove_edge(self.target_node, v0)\n        budget -= 1\n\n        # ° --- Step 2 --- ° #\n        # Get the neighbours of v0\n        v0_neighbours = list(graph.neighbors(v0))\n        # Get the neighbours of v, who are not neighbours of v0\n        v_neighbours_not_v0 = [\n            x for x in target_node_neighbours if x not in v0_neighbours\n        ]\n        # If there are fewer than b-1 such neighbours, connect v_0 to all of them\n        if len(v_neighbours_not_v0) < self.edge_budget - 1:\n            budget = len(v_neighbours_not_v0) + 1\n        # Make an ascending order list of the neighbours of v0, based on their degree\n        sorted_neighbors = sorted(v_neighbours_not_v0, key=lambda x: graph.degree[x])\n        # Connect v_0 to b-1 nodes of choice, who are neighbours of v but not of v_0\n        for i in range(budget - 1):\n            if len(sorted_neighbors) < i:\n                break\n            v0_neighbour = sorted_neighbors[i]\n            # v0_neighbour = random.choice(v_neighbours_not_v0)   # Random choice\n            graph.add_edge(v0, v0_neighbour)\n            v_neighbours_not_v0.remove(v0_neighbour)\n\n        new_community_structure = self.detection_alg.compute_community(graph)\n        return graph, new_community_structure\n","metadata":{"id":"uWP6CX_XL-oc","execution":{"iopub.status.busy":"2023-12-01T07:17:31.949915Z","iopub.execute_input":"2023-12-01T07:17:31.950343Z","iopub.status.idle":"2023-12-01T07:17:31.967216Z","shell.execute_reply.started":"2023-12-01T07:17:31.950302Z","shell.execute_reply":"2023-12-01T07:17:31.965565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Community Hiding","metadata":{"id":"8nzXkcld-dkp"}},{"cell_type":"markdown","source":"#### Safeness","metadata":{"id":"3Pxz55jz-dkq"}},{"cell_type":"code","source":"class Safeness:\n    \"\"\"Class that implements the Safeness algorithm\"\"\"\n\n    def __init__(\n        self,\n        budget: int,\n        graph: nx.Graph,\n        community_target: List[int],\n        communities_object: cdlib.NodeClustering,\n    ):\n        self.budget = budget\n        self.graph = graph.copy()\n        self.community_target = community_target\n        self.community_obj = communities_object\n\n        # Initialize as None the rest of the variable\n        self.deg = None\n        self.out_deg = None\n        self.out_ratio = None\n        self.new_adj = None\n        self.new_edge_list = None\n        self.IG_edgeList = None\n        self.pre_computation()\n\n    ############################################################################\n    #               PERFORM COMMUNITY DECEPTION with SAFENESS                  #\n    ############################################################################\n    def run(self):\n        \"\"\"\n        Run the Safeness algorithm\n\n        Returns\n        -------\n        new_graph : nx.Graph\n            New graph, where the edges have been added and removed\n        steps : int\n            Number of edges added or removed\n        \"\"\"\n        intra_considered = []\n        num_vertices = len(self.community_target)\n        beta = self.budget\n        add_gain = 0\n        del_gain = 0\n        while True:\n            # print(\"Beta: \", beta)\n            node_list = self.get_min_node_ratio_index(self.out_ratio)\n            (add_gain, add_node_ind) = self.min_index_edge_addition(\n                node_list, self.deg, self.out_deg\n            )\n            add_node = self.community_target[add_node_ind]\n            add_node_2 = self.find_external_node(\n                add_node,\n                self.community_target,\n                self.community_obj.communities,\n                self.IG_edgeList,\n            )\n            li = self.get_best_del_excl_bridges(\n                self.community_target, self.new_edge_list, self.new_adj, num_vertices\n            )\n            ((del_node, del_node_2), max_gain) = self.deletion_gain(\n                li, intra_considered, self.deg, self.out_deg, self.community_target\n            )\n            del_gain = max_gain\n            if add_gain >= del_gain and add_gain > 0:\n                self.IG_edgeList.append((add_node, add_node_2))\n                # print(\"Safeness Added edge: \", (add_node, add_node_2))\n                for i in self.community_target:\n                    deg_ = 0\n                    out_deg_ = 0\n                    for j in self.IG_edgeList:\n                        if i == j[0] or i == j[1]:\n                            deg_ = deg_ + 1\n                            if (i == j[0] and j[1] not in self.community_target) or (\n                                i == j[1] and j[0] not in self.community_target\n                            ):\n                                out_deg_ = out_deg_ + 1\n                    self.deg[self.community_target.index(i)] = deg_\n                    self.out_deg[self.community_target.index(i)] = out_deg_\n\n                for i, _ in enumerate(self.out_ratio):\n                    self.out_ratio[i] = self.out_deg[i] / self.deg[i]\n\n            elif del_gain > 0:\n                self.IG_edgeList.remove((del_node, del_node_2))\n                intra_considered.append((del_node, del_node_2))\n                # print(\"Safeness Removed edge: \", (del_node, del_node_2))\n                for i in self.community_target:\n                    deg_ = 0\n                    out_deg_ = 0\n                    for j in self.IG_edgeList:\n                        if i == j[0] or i == j[1]:\n                            deg_ = deg_ + 1\n                            if (i == j[0] and j[1] not in self.community_target) or (\n                                i == j[1] and j[0] not in self.community_target\n                            ):\n                                out_deg_ = out_deg_ + 1\n                    self.deg[self.community_target.index(i)] = deg_\n                    self.out_deg[self.community_target.index(i)] = out_deg_\n\n                for i in enumerate(self.out_ratio):\n                    self.out_ratio[i] = self.out_deg[i] / self.deg[i]\n\n                self.new_edge_list.remove((del_node, del_node_2))\n                self.new_adj[del_node].remove(del_node_2)\n                self.new_adj[del_node_2].remove(del_node)\n\n            beta = beta - 1\n\n            if beta > 0 and (add_gain > 0 or del_gain > 0):\n                continue\n            else:\n                break\n        # Build the new graph\n        new_graph = nx.Graph()\n        new_graph.add_nodes_from(self.graph.nodes())\n        new_graph.add_edges_from(self.IG_edgeList)\n        return new_graph, self.budget - beta\n\n    def get_min_node_ratio_index(self, out_ratio: List[float]):\n        \"\"\"\n        Finds the node with minimum out ratio\n\n        Parameters\n        ----------\n        out_ratio : List[float]\n            List of node ratios\n\n        Returns\n        -------\n        List[int]\n            List of node indices with minimum out ratio\n        \"\"\"\n        min_val = min(out_ratio)\n        node = []\n        for i, _ in enumerate(out_ratio):\n            if out_ratio[i] == min_val:\n                node.append(i)\n        return node\n\n    def min_index_edge_addition(self, node_list, deg, out_deg):\n        \"\"\"\n        Finds the node with minimum edge addition gain\n\n        Parameters\n        ----------\n        node_list : List[int]\n            List of node indices\n        deg : List[int]\n            Degree of nodes\n        out_deg : List[int]\n            Degree of outgoing edges\n\n        Returns\n        -------\n        Tuple[float, int]\n            Tuple of minimum edge addition gain and node index\n        \"\"\"\n        node_ind = 0\n        max_gain = 0\n        for i in node_list:\n            gain = 0.5 * ((out_deg[i] + 1) / (deg[i] + 1) - out_deg[i] / deg[i])\n            if gain > max_gain:\n                max_gain = gain\n                node_ind = i\n        return (max_gain, node_ind)\n\n    def find_external_node(self, com_node, com, graph, edges):\n        \"\"\"\n        Finds a node (not in C) such that the edge (np, nt) does not exist\n\n        Parameters\n        ----------\n        com_node : int\n            Source node, node in the target community\n        com : List[int]\n            Target community\n        graph : nx.Graph\n            Graph\n        edges : List[Tuple[int, int]]\n            List of edges\n\n        Returns\n        -------\n        j : int\n            Node not in C such that the edge (np, nt) does not exist\n        \"\"\"\n        for i in graph:\n            if i != com:\n                for j in i:\n                    if ((com_node, j) or (j, com_node)) not in edges:\n                        return j\n\n        raise Exception(\"No external node found\")\n\n    def deletion_gain(\n        self, edges, intra_considered, degrees, out_degrees, target_community\n    ) -> Tuple[Tuple[int, int], float]:\n        \"\"\"\n        Compute the deletion gain for each edge in the list of edges.\n\n        Parameters\n        ----------\n        edges : List[Tuple[int, int]]\n            List of edges in the graph.\n        intra_considered : Set[Tuple[int, int]]\n            Set of edges already considered.\n        degrees : List[int]\n            List of degrees of each node in the graph.\n        out_degrees : List[int]\n            List of out-degrees of each node in the target community.\n        target_community : List[int]\n            List of integers representing the community membership of each node.\n\n        Returns\n        -------\n        Tuple[Tuple[int, int], float]\n            The edge and its corresponding deletion gain with the highest gain.\n        \"\"\"\n        max_gain = 0\n        node_u = 0\n        node_v = 0\n        for edge in edges:\n            if edge not in intra_considered:\n                u = edge[0]\n                v = edge[1]\n                gain = (\n                    (\n                        out_degrees[target_community.index(u)]\n                        / (\n                            2\n                            * degrees[target_community.index(u)]\n                            * (degrees[target_community.index(u)] - 1)\n                        )\n                    )\n                    + (\n                        out_degrees[target_community.index(v)]\n                        / (\n                            2\n                            * degrees[target_community.index(v)]\n                            * (degrees[target_community.index(v)] - 1)\n                        )\n                    )\n                    + (1 / (len(target_community) - 1))\n                )\n                if gain > max_gain:\n                    max_gain = gain\n                    node_u = u\n                    node_v = v\n        return ((node_u, node_v), max_gain)\n\n    def get_best_del_excl_bridges(\n        self,\n        target_comm: List[int],\n        edges: List[Tuple[int, int]],\n        adjacency_list: List[List[int]],\n        num_vertices: int,\n    ) -> List[Tuple[int, int]]:\n        \"\"\"\n        Returns the list of edges that, if removed, would disconnect the graph\n        and leave only one connected component.\n\n        Parameters\n        ----------\n        target_comm : List[int]\n            List of integers representing the community membership of each node.\n        edges : List[Tuple[int, int]]\n            List of edges in the graph.\n        adjacency_list : List[List[int]]\n            The adjacency list of the graph.\n        num_vertices : int\n            The number of vertices in the graph.\n\n        Returns\n        -------\n        List[Tuple[int, int]]\n            The list of edges that, if removed, would disconnect the graph and\n            leave only one connected component.\n        \"\"\"\n        best_edges = []\n        for edge in edges:\n            adj_list_copy = copy.deepcopy(adjacency_list)\n            adj_list_copy[edge[0]].remove(edge[1])\n            adj_list_copy[edge[1]].remove(edge[0])\n            try:\n                if (\n                    self.connected_components(target_comm, num_vertices, adj_list_copy)\n                    == 1\n                ):\n                    best_edges.append(edge)\n            except:\n                continue\n        return best_edges\n\n    def dfs_util(\n        self,\n        target_comm: List[int],\n        temp: List[int],\n        v: int,\n        visited: List[bool],\n        adjacency_list: List[List[int]],\n        excluded_edge: Tuple[int, int] = None,\n    ) -> List[int]:\n        \"\"\"\n        Utility function for depth-first search algorithm.\n\n        Parameters\n        ----------\n        target_comm : List[int]\n            List of integers representing the community membership of each node.\n        temp : List[int]\n            List of nodes visited during the search.\n        v : int\n            The current node being visited.\n        visited : List[bool]\n            List of boolean values indicating whether a node has been visited or not.\n        adjacency_list : List[List[int]]\n            The adjacency list of the graph.\n\n        Returns\n        -------\n        List[int]\n            The list of nodes visited during the search.\n        \"\"\"\n        # Set current node as visited, to avoid infinite loops\n        visited[v] = True\n        temp.append(v)\n        for i in adjacency_list[target_comm[v]]:\n            if not visited[target_comm.index(i)]:\n                temp = self.dfs_util(\n                    target_comm, temp, target_comm.index(i), visited, adjacency_list\n                )\n        return temp\n\n    def connected_components(\n        self,\n        target_comm: List[int],\n        num_vertices: int,\n        adjacency_list: List[List[int]],\n        excluded_edge: Tuple[int, int] = None,\n    ) -> int:\n        \"\"\"\n        Compute the number of connected components in a graph.\n\n        Parameters\n        ----------\n        target_comm : List[int]\n            List of integers representing the community membership of each node.\n        num_vertices : int\n            The number of vertices in the graph.\n        adjacency_list : List[List[int]]\n            The adjacency list of the graph.\n        excluded_edge : Tuple[int, int], optional\n            An edge to be excluded from the graph, by default None\n\n        Returns\n        -------\n        int\n            The number of connected components in the graph.\n        \"\"\"\n        visited = [False] * num_vertices\n        # List of connected components\n        cc = []\n        for v, _ in enumerate(num_vertices):\n            if not visited[v]:\n                temp = []\n                cc.append(self.dfs_util(target_comm, temp, v, visited, adjacency_list))\n        return len(cc)\n\n    def vertices_in_connected_components(\n        self, target_comm, num_vertices, adjacency_list, node\n    ):\n        visited = []\n        cc = []\n        for i in range(num_vertices):\n            visited.append(False)\n        for v in range(num_vertices):\n            if visited[v] == False:\n                temp = []\n                cc.append(self.dfs_util(target_comm, temp, v, visited, adjacency_list))\n        cc_node_list = []\n        for i in cc:\n            tmp = []\n            for j in i:\n                tmp.append(target_comm[j])\n            cc_node_list.append(tmp)\n\n        for i in cc_node_list:\n            if node in i:\n                return len(i)\n        return 0\n\n    ############################################################################\n    #                PRE-COMPUTING FOR COMMUNITY DECEPTION                     #\n    ############################################################################\n    def pre_computation(self):\n        \"\"\"\n        Function to compute the pre-computation for the Safeness algorithm, to\n        speed up the Safeness execution.\n        \"\"\"\n        e_ = list(self.graph.edges())\n        adjacency_list = self.get_adj_list(e_)\n        num_vertices = len(self.graph.nodes())\n        self.IG_edgeList = []\n        for i in e_:\n            self.IG_edgeList.append((i[0], i[1]))\n        g = ig.Graph(directed=False)\n        g.add_vertices(num_vertices)\n        g.add_edges(self.IG_edgeList)\n\n        # Get the communities\n        communities = self.community_obj.communities\n\n        # pre_neighbours, pre_marked = self.get_target_comm_neighbours(\n        #     self.community_target, communities, adjacency_list\n        # )\n\n        self.deg = []\n        for i in self.community_target:\n            self.deg.append(g.vs[i].degree())\n\n        self.out_deg = []\n        for i in self.community_target:\n            out = 0\n            for j in adjacency_list[i]:\n                if j not in self.community_target:\n                    out = out + 1\n            self.out_deg.append(out)\n\n        self.out_ratio = []\n        for j, _ in enumerate(self.out_deg):\n            self.out_ratio.append(self.out_deg[j] / self.deg[j])\n\n        self.new_adj = {}\n        for j in adjacency_list.keys():\n            if j in self.community_target:\n                self.new_adj[j] = []\n                for k in adjacency_list[j]:\n                    if k in self.community_target:\n                        self.new_adj[j].append(k)\n\n        self.new_edge_list = []\n        for j in self.IG_edgeList:\n            if j[0] in self.community_target and j[1] in self.community_target:\n                self.new_edge_list.append(j)\n\n    def num_comm(\n        self, target_comm: List[int], communities: List[List[int]]\n    ) -> Tuple[int, List]:\n        \"\"\"\n        Find the communities in which the nodes of the target community are present.\n\n        Parameters\n        ----------\n        target_comm : List[int]\n            Target community, list of nodes\n        communities : List[List[int]]\n            List of communities, each community is a list of nodes\n\n        Returns\n        -------\n        len(uni_comm) : int\n            Number of communities in which the nodes of the target community are present\n        comm_list : List[List[int]]\n            List of communities in which the nodes of the target community are present\n\n        \"\"\"\n        uni_comm = []\n        comm_list = []\n        for node in target_comm:\n            for c in communities:\n                if node in c:\n                    comm_list.append(c)\n                    if c not in uni_comm:\n                        uni_comm.append(c)\n                        break\n        return len(uni_comm), comm_list\n\n    def get_target_comm_neighbours(\n        self,\n        target_comm: List[int],\n        communities: List[List[int]],\n        adjacency_list: List[int],\n    ) -> Tuple[List[int], List[int]]:\n        \"\"\"\n        Given a target community, a list of communities, and an adjacency list,\n        returns a list of the indices of the communities that have at least one\n        neighbor in the target community, as well as a dictionary of marked nodes.\n\n        Parameters\n        ----------\n        target_comm : List[int]\n            A list of nodes representing the target community\n        communities : List[List[int]]\n            A list of lists, where each list contains the nodes of a community\n        adjacency_list : dict\n            A dictionary where the keys are nodes and the values are lists of the neighbors of the corresponding node\n\n        Returns\n        -------\n        List : List\n            A list of integers representing the indices of the communities that have at least one neighbor in the target community\n        Marked : dict\n            A dictionary where the keys are nodes that have been marked and the values are the same as the keys\n        \"\"\"\n        neighbors_list = []\n        marked = dict()\n        for node in target_comm:\n            for j in adjacency_list[node]:\n                if j not in marked:\n                    for k, _ in enumerate(communities):\n                        if j in communities[k]:\n                            neighbors_list.append(k)\n                            marked[j] = j\n        return neighbors_list, marked\n\n    def check_neighbours(self, neighbours: List[int], communities: List[List[int]]):\n        \"\"\"\n        Given a list of node IDs `neighbours` and a list of communities `communities`,\n        returns a list of indices of the communities that contain at least one of the\n        nodes in `neighbours`.\n\n        Parameters\n        ----------\n        neighbours : List[int]\n            A list of node IDs.\n        communities : List[List[int]]\n            A list of lists, where each inner list contains the node IDs of a community.\n\n        Returns\n        -------\n        list\n            A list of integers representing the indices of the communities that contain\n            at least one of the nodes in `neighbours`.\n        \"\"\"\n        ctr = 0\n        community_list = []\n        for i, community in enumerate(communities):\n            for node in community:\n                if node in neighbours:\n                    community_list.append(community)\n                    ctr += 1\n                if ctr == len(neighbours):\n                    return community_list\n        return community_list\n\n    def get_entropy(self, labels, base=None):\n        \"\"\"\n        Calculate the entropy of a given set of labels.\n\n        Parameters\n        ----------\n        labels : array_like\n            A 1-D array of labels.\n        base : float, optional\n            The logarithmic base to use for calculating the entropy. Default is None, which uses the natural logarithm.\n\n        Returns\n        -------\n        float\n            The entropy of the label distribution.\n        \"\"\"\n        values, counts = np.unique(labels, return_counts=True)\n        return entropy(counts, base=base)\n\n    def get_adj_list(self, edge_list: List[Tuple[int, int]]):\n        \"\"\"\n        Returns the adjacency list of a graph given its edge list.\n\n        Parameters\n        ----------\n        edge_list : list of tuples\n            A list of tuples representing the edges of the graph.\n\n        Returns\n        -------\n        dict\n            A dictionary where the keys are the nodes of the graph and the values are lists of the nodes adjacent to the key node.\n        \"\"\"\n        adjacency_list = {}\n        for i, _ in enumerate(edge_list):\n            edge = edge_list[i]\n            # Source Node\n            s = edge[0]\n            # Target Node\n            t = edge[1]\n            if s in adjacency_list:\n                adjacency_list[s].append(t)\n            else:\n                adjacency_list[s] = [t]\n            if t in adjacency_list:\n                adjacency_list[t].append(s)\n            else:\n                adjacency_list[t] = [s]\n        return adjacency_list","metadata":{"id":"9kyY5K-b-dkq","execution":{"iopub.status.busy":"2023-12-01T07:17:32.019354Z","iopub.execute_input":"2023-12-01T07:17:32.020490Z","iopub.status.idle":"2023-12-01T07:17:32.100594Z","shell.execute_reply.started":"2023-12-01T07:17:32.020435Z","shell.execute_reply":"2023-12-01T07:17:32.099163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Modularity","metadata":{"id":"LYY_RdDcbmXD"}},{"cell_type":"code","source":"\nclass Modularity:\n    \"\"\"Class that implements the Modularity algorithm\"\"\"\n\n    def __init__(\n        self,\n        beta: int,\n        graph: nx.Graph,\n        community_target: List[int],\n        communities_object: cdlib.NodeClustering,\n        detection_alg: callable,\n    ):\n        self.beta = beta\n        self.graph = graph.copy()\n        self.community_target = community_target\n        self.community_obj = communities_object\n        self.detection_alg = detection_alg\n\n        self.old_modularity = nx.community.modularity(\n            graph, communities_object.communities\n        )\n\n        # Randomly select an intra-community edge\n        self.intra_community_edges = [\n            edge\n            for edge in self.graph.edges()\n            if edge[0] in self.community_target and edge[1] in self.community_target\n        ]\n\n    def process_edge(self, edge):\n        gain, communities_del, mod_after_del = self.get_del_loss(edge[0], edge[1])\n        return edge, {\n            \"gain\": gain,\n            \"communities\": communities_del,\n            \"mod_after\": mod_after_del,\n        }\n\n    def compute_and_sort_com_degrees(\n        self, graph: nx.Graph, communities: List[List[int]]\n    ) -> List[Tuple[int, Dict[str, Union[List[int], int]]]]:\n        \"\"\"\n        Compute and sort the degree of each community in the given graph.\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            The input graph.\n        communities : List[List[int]]\n            The list of communities.\n\n        Returns\n        -------\n        List[Tuple[int, Dict[str, Union[List[int], int]]]]\n            The list of communities sorted by their degree, where each\n            community is represented as a tuple containing the community\n            index and a dictionary with the community nodes and their degree.\n        \"\"\"\n        community_degree = {}\n        for i, community in enumerate(communities):\n            community_degree[i] = {\n                \"community\": community,\n                \"degree\": sum(graph.degree(n) for n in community),\n            }\n        community_degree = sorted(\n            community_degree.items(), key=lambda x: x[1][\"degree\"], reverse=True\n        )\n        return community_degree\n\n    def get_eta(self):\n        # Given the community structure, compute for each community the sum\n        # of internal and external edges\n        eta = 0\n        for community in self.community_obj.communities:\n            # Compute subgraph of the community\n            subgraph = self.graph.subgraph(community)\n            # Compute the number of edges in the subgraph\n            num_edges = subgraph.number_of_edges()\n            # Compute the external edges of the community\n            for node in community:\n                for neighbor in self.graph.neighbors(node):\n                    if neighbor not in community:\n                        num_edges += 1\n            eta += num_edges\n        return eta\n\n    def get_delta(self):\n        delta = 0\n        for community in self.community_obj.communities:\n            delta += sum(self.graph.degree(node) ** 2 for node in community)\n        return delta\n\n    def get_add_loss_fast(self, Ci, Cj) -> float:\n        Ci_deg = sum(self.graph.degree(n) for n in Ci)\n        Cj_deg = sum(self.graph.degree(n) for n in Cj)\n        m = self.graph.number_of_edges()\n        first_component = self.get_eta() / m * (m + 1)\n        second_component = (\n            2 * m**2 * (Ci_deg + Cj_deg + 1) - self.get_delta() * (2 * m + 1)\n        ) / (4 * m**2 * (m + 1) ** 2)\n        return first_component + second_component\n\n    def get_del_loss_fast(self, Ci):\n        Ci_deg = (\n            sum(self.graph.degree(n) for n in Ci) - 2\n        )  # subtract the edge to remove\n        m = self.graph.number_of_edges()\n        first_component = m - self.get_eta() / m * (m - 1)\n        second_component = (\n            self.get_delta() * (2 * m - 1) - 4 * m**2 * (Ci_deg - 1)\n        ) / (4 * m**2 * (m - 1) ** 2)\n        return first_component + second_component\n\n    def get_add_loss(\n        self, np: int, nt: int\n    ) -> Tuple[float, cdlib.NodeClustering, float]:\n        \"\"\"\n        Computes the modularity gain, new communities and new modularity\n        after adding an edge between two nodes.\n\n        Parameters\n        ----------\n        np : int\n            The index of the first node.\n        nt : int\n            The index of the second node.\n\n        Returns\n        -------\n        Tuple[float, cdlib.NodeClustering, float]\n            A tuple containing the modularity gain, the new communities and\n            the new modularity.\n        \"\"\"\n        graph = self.graph.copy()\n        graph.add_edge(np, nt)\n        communities_after = self.detection_alg.compute_community(graph)\n        mod_after = nx.community.modularity(graph, communities_after.communities)\n        gain = mod_after - self.old_modularity\n        graph.remove_edge(np, nt)\n        return gain, communities_after, mod_after\n\n    def get_del_loss(\n        self, nk: int, nl: int\n    ) -> Tuple[float, cdlib.NodeClustering, float]:\n        \"\"\"\n        Compute the modularity gain obtained by removing the edge between nodes nk and nl.\n\n        Parameters\n        ----------\n        nk : int\n            The first node of the edge to remove.\n        nl : int\n            The second node of the edge to remove.\n\n        Returns\n        -------\n        Tuple[float, cdlib.NodeClustering, float]\n            A tuple containing the modularity gain obtained by removing the edge, the new node clustering, and the new modularity value.\n        \"\"\"\n        graph = self.graph.copy()\n        mod_before = self.old_modularity\n\n        graph.remove_edge(nk, nl)\n        communities_after = self.detection_alg.compute_community(graph)\n        mod_after = nx.community.modularity(graph, communities_after.communities)\n\n        gain = mod_after - mod_before\n        graph.add_edge(nk, nl)\n        return gain, communities_after, mod_after\n\n    def run(self) -> Tuple[nx.Graph, int, cdlib.NodeClustering]:\n        \"\"\"\n        Executes the community hiding algorithm on the input graph.\n\n        Returns\n        -------\n        Tuple[nx.Graph, int, cdlib.NodeClustering] : [graph, iterations, communities]\n            A tuple containing the modified graph, the number of iterations\n            performed, and the resulting node clustering.\n        \"\"\"\n        graph = self.graph\n        beta = self.beta\n        communities = self.community_obj\n\n        while beta > 0:\n            deg_C = self.compute_and_sort_com_degrees(graph, communities.communities)\n            MLadd = -1\n            if len(deg_C) > 1:\n                Ci = deg_C[0][1][\"community\"]\n                Cj = deg_C[1][1][\"community\"]\n                # Find the best edge to add\n                np, nt = next(\n                    (\n                        (np, nt)\n                        for np in Ci\n                        for nt in Cj\n                        if np != nt and not graph.has_edge(np, nt)\n                    ),\n                    (None, None),\n                )\n                if np is not None and nt is not None:\n                    MLadd = self.get_add_loss_fast(Ci, Cj)\n                    # MLadd, communities_add, mod_after_add = self.get_add_loss(np, nt)\n\n            MLdel = self.get_del_loss_fast(self.community_target)\n\n            if MLdel >= MLadd and MLdel > 0:\n                # Randomly select an intra-community edge\n                subgraph = graph.subgraph(self.community_target)\n                nk, nl = random.choice(list(subgraph.edges()))\n                graph.remove_edge(nk, nl)\n                self.old_modularity += MLdel\n            elif MLadd > 0:\n                graph.add_edge(np, nt)\n                self.old_modularity += MLadd\n\n            beta -= 1\n            if MLadd <= 0 and MLdel <= 0:\n                break\n\n        # Compute the new communities\n        communities = self.detection_alg.compute_community(graph)\n        return graph, self.beta - beta, communities\n","metadata":{"id":"u54YGFv9bo8U","execution":{"iopub.status.busy":"2023-12-01T07:17:32.104120Z","iopub.execute_input":"2023-12-01T07:17:32.105452Z","iopub.status.idle":"2023-12-01T07:17:32.146094Z","shell.execute_reply.started":"2023-12-01T07:17:32.105401Z","shell.execute_reply":"2023-12-01T07:17:32.144393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metrics","metadata":{"id":"vozttQoQbSeq"}},{"cell_type":"markdown","source":"##### Deception Score","metadata":{"id":"_roZ5e0G-dkp"}},{"cell_type":"code","source":"\nclass DeceptionScore(object):\n    \"\"\"Deception score of a community detection algorithm.\"\"\"\n\n    def __init__(self, community_target: List[int]) -> None:\n        self.community_target = community_target\n\n    @staticmethod\n    def recall(g_i: List[int], community_target: List[int]) -> float:\n        \"\"\"Calculate recall score of a community g_i\n\n        Parameters\n        ----------\n        g_i : List[int]\n            Community found by a community detection algorithm.\n\n        Returns\n        -------\n        float\n            Recall score of g_i.\n        \"\"\"\n        # Number of members in g_i that are also in our community\n        members_in_g_i = len(set(community_target) & set(g_i))\n        return members_in_g_i / len(community_target)\n\n    @staticmethod\n    def precision(g_i: List[int], community_target: List[int]) -> float:\n        \"\"\"Calculate precision score of a community g_i\n\n        Parameters\n        ----------\n        g_i : List[int]\n            Community found by a community detection algorithm.\n\n        Returns\n        -------\n        float\n            Precision score of g_i.\n        \"\"\"\n        # Number of members in G_i that are also in our community\n        members_in_g_i = len(set(community_target) & set(g_i))\n        return members_in_g_i / len(g_i)\n\n    @DeprecationWarning\n    def compute_deception_score(\n        self, community_structure: List[List[int]], connected_components: int\n    ) -> float:\n        \"\"\"Calculate deception score of a community detection algorithm.\n\n        Parameters\n        ----------\n        community_structure : List(List(int))\n            Community structure found by a community detection algorithm.\n        connected_components : int\n            Number of connected components in the graph.\n\n        Returns\n        -------\n        deception_score : float\n            Deception score of a community detection algorithm.\n        \"\"\"\n        # Number of intersecting nodes between the community structure and community target\n        n_intersecting_nodes = [\n            g_i\n            for g_i in community_structure\n            if len(set(self.community_target) & set(g_i)) > 0\n        ]\n\n        recall = max(\n            [self.recall(g_i, self.community_target) for g_i in community_structure]\n        )\n        precision = sum(\n            [self.precision(g_i, self.community_target) for g_i in n_intersecting_nodes]\n        )\n\n        # Ideal situation occurs when each member of the community target is\n        # placed in a different community and the value of the maximum recall\n        # is lower possible.\n        assert (\n            len(self.community_target) - 1 > 0\n        ), \"Community target must have at least 2 members.\"\n        community_spread = 1 - (connected_components - 1) / (\n            len(self.community_target) - 1\n        )\n\n        # Ideal situation occurs when each member of the community structure\n        # contains little percentage of the community target.\n        assert (\n            len(n_intersecting_nodes) > 0\n        ), \"Community structure must have at least 1 member.\"\n        community_hiding = 0.5 * (1 - recall) + 0.5 * (\n            1 - precision / len(n_intersecting_nodes)\n        )\n\n        # Deception score is the product of community spread and community hiding.\n        deception_score = community_spread * community_hiding\n        return deception_score\n\n    # TEST\n    def get_deception_score(self, graph, community_structure: List[List[int]]):\n        \"\"\"\n        New version of the deception score, based on the repository:\n            - https://github.com/vfionda/BHC/tree/main\n\n        Parameters\n        ----------\n        community_structure : List[List[int]]\n            _description_\n\n        Returns\n        -------\n        _type_\n            _description_\n        \"\"\"\n        number_communities = len(community_structure)\n\n        # Number of the target community members in the various communities\n        member_for_community = np.zeros(number_communities, dtype=int)\n\n        for i in range(number_communities):\n            for node in community_structure[i]:\n                if node in self.community_target:\n                    member_for_community[i] += 1\n\n        # ratio of the targetCommunity members in the various communities\n        ratio_community_members = [\n            members_for_c / len(com)\n            for (members_for_c, com) in zip(member_for_community, community_structure)\n        ]\n\n        # In how many commmunities are the members of the target spread?\n        spread_members = sum([1 if mc > 0 else 0 for mc in member_for_community])\n\n        second_part = 1 / 2 * ((spread_members - 1) / number_communities) + 1 / 2 * (\n            1 - sum(ratio_community_members) / spread_members\n        )\n\n        # induced subraph only on target community nodes\n        num_components = nx.number_connected_components(\n            graph.subgraph(self.community_target)\n        )\n\n        denominator = len(self.community_target) - 1\n        if denominator == 0:\n            denominator = 1\n        first_part = 1 - ((num_components - 1) / denominator)\n        dec_score = first_part * second_part\n        return dec_score","metadata":{"id":"7YApsEpM-dkq","execution":{"iopub.status.busy":"2023-12-01T07:17:32.148337Z","iopub.execute_input":"2023-12-01T07:17:32.148854Z","iopub.status.idle":"2023-12-01T07:17:32.174975Z","shell.execute_reply.started":"2023-12-01T07:17:32.148810Z","shell.execute_reply":"2023-12-01T07:17:32.173806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Similarity Metrics","metadata":{"id":"9o-92qV6HfNW"}},{"cell_type":"code","source":"\nclass CommunitySimilarity:\n    \"\"\"Class to compute the similarity between two lists of integers\"\"\"\n\n    def __init__(self, function_name: str) -> None:\n        self.function_name = function_name\n\n    def select_similarity_function(self) -> Callable:\n        \"\"\"\n        Select the similarity function to use\n\n        Returns\n        -------\n        Callable\n            Similarity function to use\n        \"\"\"\n        if self.function_name == SimilarityFunctionsNames.JAC.value:\n            return self.jaccard_similarity\n        elif self.function_name == SimilarityFunctionsNames.OVE.value:\n            return self.overlap_similarity\n        elif self.function_name == SimilarityFunctionsNames.SOR.value:\n            return self.sorensen_similarity\n        else:\n            raise Exception(\"Similarity function not found\")\n\n    @staticmethod\n    def jaccard_similarity(a: List[int], b: List[int]) -> float:\n        \"\"\"\n        Compute the Jaccard similarity between two lists, A and B:\n            J(A,B) = |A ∩ B| / |A U B|\n\n        Parameters\n        ----------\n        a : List[int]\n            First List\n        b : List[int]\n            Second List\n\n        Returns\n        -------\n        float\n            Jaccard similarity between the two lists, between 0 and 1\n        \"\"\"\n        assert len(a) > 0, \"List A must be not empty\"\n        # assert len(b) > 0, \"List B must be not empty\"\n        if len(b) == 0:\n            return 0\n        # Convert lists to sets\n        a_set = set(a)\n        b_set = set(b)\n        # Compute the intersection and union\n        intersection = a_set.intersection(b_set)\n        union = a_set.union(b_set)\n        return len(intersection) / len(union)\n\n    @staticmethod\n    def overlap_similarity(a: List[int], b: List[int]) -> float:\n        \"\"\"\n        Compute the Overlap similarity between two lists, A and B:\n            O(A,B) = |A ∩ B| / min(|A|, |B|)\n\n        Parameters\n        ----------\n        a : List[int]\n            First List\n        b : List[int]\n            Fist List\n\n        Returns\n        -------\n        float\n            Overlap coefficient between the two lists, value between 0 and 1\n        \"\"\"\n        assert len(a) > 0, \"List A must be not empty\"\n        # assert len(b) > 0, \"List B must be not empty\"\n        if len(b) == 0:\n            return 0\n        # Convert lists to sets\n        a_set = set(a)\n        b_set = set(b)\n        # Compute the intersection\n        intersection = a_set.intersection(b_set)\n        return len(intersection) / min(len(a_set), len(b_set))\n\n    @staticmethod\n    def sorensen_similarity(a: List[int], b: List[int]) -> float:\n        \"\"\"\n        Compute the Sorensen similarity between two lists, A and B:\n            S(A,B) = 2 * |A ∩ B| / (|A| + |B|)\n\n        Parameters\n        ----------\n        a : List[int]\n            First List\n        b : List[int]\n            Second List\n\n        Returns\n        -------\n        float\n            Sorensen similarity between the two lists, between 0 and 1\n        \"\"\"\n        assert len(a) > 0, \"List A must be not empty\"\n        # assert len(b) > 0, \"List B must be not empty\"\n        if len(b) == 0:\n            return 0\n\n        # Convert lists to sets\n        a_set = set(a)\n        b_set = set(b)\n        # Compute the intersection\n        intersection = a_set.intersection(b_set)\n        return 2 * len(intersection) / (len(a_set) + len(b_set))\n\n\nclass GraphSimilarity:\n    \"\"\"Class to compute the similarity between two graphs\"\"\"\n\n    def __init__(self, function_name: str) -> None:\n        \"\"\"\n        Initialize the GraphSimilarity class\n\n        Parameters\n        ----------\n        function_name : str\n            Name of the similarity function to use\n        \"\"\"\n        self.function_name = function_name\n\n    def select_similarity_function(self) -> Callable:\n        \"\"\"\n        Select the similarity function to use\n\n        Returns\n        -------\n        Callable\n            Similarity function to use\n        \"\"\"\n        if self.function_name == SimilarityFunctionsNames.GED.value:\n            return self.graph_edit_distance\n        elif self.function_name == SimilarityFunctionsNames.JAC_1.value:\n            return self.jaccard_similarity_1\n        elif self.function_name == SimilarityFunctionsNames.JAC_2.value:\n            return self.jaccard_similarity_2\n        else:\n            raise Exception(\"Similarity function not found\")\n\n    def graph_edit_distance(self, g: nx.Graph, h: nx.Graph) -> float:\n        \"\"\"\n        Compute the graph edit distance between two graphs, then normalize it\n        using a null graph:\n            GED(G1,G2)/[GED(G1,G0) + GED(G2,G0)]  with G0 = null graph\n\n        Parameters\n        ----------\n        g : nx.Graph\n            First graph\n        h : nx.Graph\n            Second graph\n\n        Returns\n        -------\n        graph_distance : float\n            Graph edit distance between the two graphs normalized\n        \"\"\"\n        # Slow, but precise\n        # graph_distance = nx.graph_edit_distance(self.graph, self.old_graph)\n\n        # Faster approximation of the graph edit distance\n        graph_distance = next(nx.optimize_graph_edit_distance(g, h))\n        # Normalize\n        g_dist_1 = next(nx.optimize_graph_edit_distance(g, nx.null_graph()))\n        g_dist_2 = next(nx.optimize_graph_edit_distance(h, nx.null_graph()))\n        graph_distance /= g_dist_1 + g_dist_2\n        return graph_distance\n\n    def jaccard_similarity_1(self, g: nx.Graph, h: nx.Graph) -> float:\n        \"\"\"\n        Compute the Jaccard Similarity between two graphs\n        J(G, H) = (∑_{i,j} |A_{ij}^G - A_{i,j}^H|) / (∑_{i,j} max(A_{i,j)^G, A_{i,j}^H))\n\n        Parameters\n        ----------\n        g : nx.Graph\n            First graph\n        h : nx.Graph\n            Second graph\n\n        Returns\n        -------\n        jaccard_sim : float\n            Jaccard Similarity between the two graphs, between 0 and 1,\n            where 0 means the two graphs are identical and 1 means they are\n            completely different\n        \"\"\"\n        # Get adjacency matrices\n        g_matrix = nx.to_numpy_array(g)\n        h_matrix = nx.to_numpy_array(h)\n        # Ensure G and H have the same shape\n        if g_matrix.shape != h_matrix.shape:\n            raise ValueError(\"Input matrices must have the same shape.\")\n        # Calculate the numerator (sum of absolute differences)\n        numerator = np.sum(np.abs(g_matrix - h_matrix))\n        # Calculate the denominator (sum of element-wise maximum values)\n        denominator = np.sum(np.maximum(g_matrix, h_matrix))\n        # Calculate the Jaccard similarity\n        jaccard_sim = numerator / denominator\n        return jaccard_sim\n\n    def jaccard_similarity_2(self, g: nx.Graph, h: nx.Graph) -> float:\n        \"\"\"\n        Compute the Jaccard Similarity between two graphs, second version\n\n        Parameters\n        ----------\n        g : nx.Graph\n            First graph\n        h : nx.Graph\n            Second graph\n\n        Returns\n        -------\n        float\n            jaccard similarity between the two graphs\n        \"\"\"\n        g = g.edges()\n        h = h.edges()\n        i = set(g).intersection(h)\n        j = round(len(i) / (len(g) + len(h) - len(i)), 3)\n        # Normalize to have 0 if the graphs are identical and 1 if they are\n        # completely different\n        return 1 - j","metadata":{"id":"aUCei7YWHhtl","execution":{"iopub.status.busy":"2023-12-01T07:17:32.177484Z","iopub.execute_input":"2023-12-01T07:17:32.178383Z","iopub.status.idle":"2023-12-01T07:17:32.211029Z","shell.execute_reply.started":"2023-12-01T07:17:32.178346Z","shell.execute_reply":"2023-12-01T07:17:32.209946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Enviroment","metadata":{"id":"-l6FamFa4qN2"}},{"cell_type":"code","source":"class GraphEnvironment(object):\n    \"\"\"Enviroment where the agent will act, it will be a graph with a community\"\"\"\n\n    def __init__(\n        self,\n        graph_path: str = HyperParams.GRAPH_NAME.value,\n        community_detection_algorithm: str = HyperParams.DETECTION_ALG_NAME.value,\n        beta: float = HyperParams.BETA.value,\n        tau: float = HyperParams.TAU.value,\n        community_similarity_function: str = SimilarityFunctionsNames.SOR.value,\n        graph_similarity_function: str = SimilarityFunctionsNames.JAC_1.value,\n    ) -> None:\n        \"\"\"Constructor for Graph Environment\n        Parameters\n        ----------\n        graph_path : str, optional\n            Path of the graph to load, by default HyperParams.GRAPH_NAME.value\n        community_detection_algorithm : str\n            Name of the community detection algorithm to use\n        beta : float, optional\n            Hyperparameter for the edge budget, value between 0 and 100\n        tau : float, optional\n            Strength of the deception constraint, value between 0 and 1, with 1\n            we have a soft constraint, hard constraint otherwise, by default\n            HyperParams.T.value\n        community_similarity_function : str, optional\n            Name of the community similarity function to use, by default\n            SimilarityFunctionsNames.SOR.value\n        graph_similarity_function : str, optional\n            Name of the graph similarity function to use, by default\n            SimilarityFunctionsNames.JAC_1.value\n        \"\"\"\n        random.seed(time.time())\n        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n        # ° ---- GRAPH ---- ° #\n        self.env_name = None\n        self.graph = None\n        self.original_graph = None\n        self.old_graph = None\n        self.n_connected_components = None\n        self.set_graph(graph_path)\n\n        # ° ---- NODE FEATURES ---- ° #\n        # Set the node features of the graph, using Node2Vec\n        self.embedding_model = None\n        self.embedding = None\n        # self.set_node_features()\n\n        # ° ---- HYPERPARAMETERS ---- ° #\n        assert beta >= 0 and beta <= 100, \"Beta must be between 0 and 100\"\n        assert tau >= 0 and tau <= 1, \"T value must be between 0 and 1\"\n        # Percentage of edges to remove\n        self.beta = beta\n        self.tau = tau\n        # Weights for the reward and the penalty\n        self.lambda_metric = None  # lambda_metric\n        self.alpha_metric = None  # alpha_metric\n\n        # ° ---- SIMILARITY FUNCTIONS ---- ° #\n        self.community_similarity = None\n        self.graph_similarity = None\n        self.set_similarity_funtions(\n            community_similarity_function, graph_similarity_function\n        )\n\n        # ° ---- COMMUNITY DETECTION ---- ° #\n        self.detection_alg = None\n        self.detection = None\n        self.old_penalty_value = None\n        self.original_community_structure = None\n        self.old_community_structure = None\n        self.new_community_structure = None\n        self.prob_dist = None\n        self.sorted_communities = None\n        self.preferred_community_size = HyperParams.PREFERRED_COMMUNITY_SIZE.value[0]\n        self.set_communities(community_detection_algorithm)\n\n        # ° ---- COMMUNITY DECEPTION ---- ° #\n        self.community_target = None\n        self.node_target = None\n        self.change_target_community()\n\n        # ° ---- REWIRING STEP ---- ° #\n        self.edge_budget = 0\n        self.used_edge_budget = 0\n        self.max_steps = 0\n        self.stop_episode = False\n        self.rewards = 0\n        self.old_rewards = 0\n        self.possible_actions = None\n        self.len_add_actions = None\n        self.set_rewiring_budget()\n\n        # ° ---- PRINT ENVIRONMENT INFO ---- ° #\n        # Print the environment information\n        self.print_env_info()\n\n    ############################################################################\n    #                       EPISODE RESET FUNCTIONS                            #\n    ############################################################################\n    def reset(self, graph_reset=True) -> nx.Graph:\n        \"\"\"\n        Reset the environment\n\n        Parameters\n        ----------\n        graph_reset : bool, optional\n            Whether to reset the graph to the original state, by default True\n\n        Returns\n        -------\n        self.graph : nx.Graph\n            Graph state after the reset, i.e. the original graph\n        \"\"\"\n        self.used_edge_budget = 0\n        self.stop_episode = False\n        self.rewards = 0\n        self.old_rewards = 0\n        if graph_reset:\n            self.graph = self.original_graph.copy()\n        self.old_graph = None\n        self.old_penalty_value = 0\n        self.old_community_structure = self.original_community_structure\n        self.possible_actions = self.get_possible_actions()\n        return self.graph\n\n    def change_target_node(self, node_target: int = None) -> None:\n        \"\"\"\n        Change the target node to remove from the community\n\n        Parameters\n        ----------\n        node_target : int, optional\n            Node to remove from the community, by default None\n        \"\"\"\n        if node_target is None:\n            # Choose a node randomly from the community\n            old_node = self.node_target\n            while self.node_target == old_node:\n                random.seed(time.time())\n                self.node_target = random.choice(self.community_target)\n        else:\n            self.node_target = node_target\n\n    def change_target_community(\n        self, community: List[int] = None, node_target: int = None\n    ) -> None:\n        \"\"\"\n        Change the target community from which we want to hide the node\n\n        Parameters\n        ----------\n        community : List[int]\n            Community of node we want to remove from it\n        node_target : int\n            Node to remove from the community\n        \"\"\"\n        if community is None:\n            # ° METHOD 1: Select randomly a new community target different from the last one\n            if HyperParams.COMMUNITY_CHANGE_METHOD.value == 1:\n                self.random_community()\n            # ° METHOD 2: Get the community with the highest number of nodes\n            elif HyperParams.COMMUNITY_CHANGE_METHOD.value == 2:\n                self.fixed_community()\n            # ° METHOD 3: Choose the community based on the distribution of the number of nodes in the communities\n            elif HyperParams.COMMUNITY_CHANGE_METHOD.value == 3:\n                self.distribution_community()\n            else:\n                raise ValueError(\n                    f\"Invalid community change method: {HyperParams.COMMUNITY_CHANGE_METHOD.value}. Must be 1, 2, or 3.\"\n                )\n        else:\n            self.community_target = community\n        # Change the target node to remove from the community\n        self.change_target_node(node_target=node_target)\n\n    def random_community(self) -> None:\n        \"\"\"\n        Choose a new community target randomly\n        \"\"\"\n        old_community = self.community_target.copy()\n        done = False\n        while not done:\n            random.seed(time.time())\n            self.community_target = random.choice(\n                self.original_community_structure.communities\n            )\n            # Check condition on new community\n            if (\n                len(self.community_target) > 1\n                and self.community_target != old_community\n            ) or len(self.original_community_structure.communities) < 2:\n                done = True\n        del old_community\n\n    def fixed_community(self) -> None:\n        \"\"\"\n        Choose the community with the length closest to the half of the maximum\n        length of the communities.\n        \"\"\"\n        communities = self.original_community_structure.communities\n        communities_len = [len(c) for c in communities]\n        preferred_size = (\n            int(np.ceil(max(communities_len) * self.preferred_community_size)) # / 2\n        )\n        closest = min(communities_len, key=lambda x: abs(x - preferred_size))\n        self.community_target = communities[communities_len.index(closest)]\n\n    def distribution_community(self, min_len: int = 10) -> None:\n        \"\"\"\n        Choose a community based on the distribution of the number of nodes in\n        the communities\n        \n        Parameters\n        ----------\n        min_len : int, optional\n            Minimum size of the community, by default 10\n        \"\"\"\n        communities = self.original_community_structure.communities\n        # If the number of communities is less than 10, select a community randomly\n        if len(communities) < 10:\n            self.community_target = random.choice(communities)\n            return\n        # Compute the average number of nodes in the communities\n        avg_nodes = np.mean([len(c) for c in communities])\n        # Get the length of the community with the highest number of nodes\n        max_nodes = max(len(community) for community in communities)\n\n        # min_len = 0.4 * max_nodes\n        max_len = 0.8 * max_nodes\n        if avg_nodes < min_len:\n            min_len = 2\n        # Filter communities based on size constraint\n        filtered_communities = [\n            c\n            for c in communities\n            if len(c) > min_len and len(c) < max_len and len(c) < 5000\n        ]\n        # Randomly select a community from the filtered list\n        self.community_target = random.choice(filtered_communities)\n\n    ############################################################################\n    #                      EPISODE STEP FUNCTIONS                              #\n    ############################################################################\n    def step(self, action: int) -> Tuple[nx.Graph, float, bool, bool]:\n        \"\"\"\n        Step function for the environment\n\n        Parameters\n        ----------\n        action : int\n            Integer representing a node in the graph, it will be the destination\n            node of the rewiring action (out source node is always the target node).\n\n        Returns\n        -------\n        self.graph : nx.Graph\n            Graph state after the action\n        self.rewards : float\n            Reward of the agent\n        self.stop_episode : bool\n            If the budget for the graph rewiring is exhausted, or the target\n            node does not belong to the community anymore, the episode is finished\n        done : bool\n            Whether the episode is finished, if the target node does not belong\n            to the community anymore, the episode is finished.\n        \"\"\"\n        # ° ---- ACTION ---- ° #\n        # Save the graph state before the action, used to compute the metrics\n        self.old_graph = self.graph.copy()\n        # Take action, add/remove the edge between target node and the model output\n        budget_consumed = self.apply_action(action)\n        # Set a negative reward if the action has not been applied\n        if budget_consumed == 0:\n            self.rewards = -1\n            # The state is the same as before\n            # return self.data_pyg, self.rewards, self.stop_episode\n            return self.graph, self.rewards, self.stop_episode, False\n\n        # ° ---- COMMUNITY DETECTION ---- ° #\n        # Compute the community structure of the graph after the action\n        self.new_community_structure = self.detection.compute_community(self.graph)\n\n        # ° ---- REWARD ---- ° #\n        self.rewards, done = self.get_reward()\n        # If the target node does not belong to the community anymore,\n        # the episode is finished\n        if done:\n            self.stop_episode = True\n\n        # ° ---- BUDGET ---- ° #\n        # Compute used budget\n        self.used_edge_budget += budget_consumed\n        # If the budget for the graph rewiring is exhausted, stop the episode\n        if self.edge_budget - self.used_edge_budget < 1:\n            self.stop_episode = True\n            # If the budget is exhausted, and the target node still belongs to\n            # the community, the reward is negative\n            # if not done:\n            #    self.rewards = -2\n\n        self.old_community_structure = self.new_community_structure\n        return self.graph, self.rewards, self.stop_episode, done\n\n    def apply_action(self, action: int) -> int:\n        \"\"\"\n        Applies the action to the graph, if there is an edge between the two\n        nodes, it removes it, otherwise it adds it\n\n        Parameters\n        ----------\n        action : int\n            Integer representing a node in the graph, it will be the destination\n            node of the rewiring action (out source node is always the target node).\n\n        Returns\n        -------\n        budget_consumed : int\n            Amount of budget consumed, 1 if the action has been applied, 0 otherwise\n        \"\"\"\n        action = (self.node_target, action)\n        # We need to take into account both the actions (u,v) and (v,u)\n        action_reversed = (action[1], action[0])\n        if action in self.possible_actions[\"ADD\"]:\n            self.graph.add_edge(*action, weight=1)\n            self.possible_actions[\"ADD\"].remove(action)\n            return 1\n        elif action_reversed in self.possible_actions[\"ADD\"]:\n            self.graph.add_edge(*action_reversed, weight=1)\n            self.possible_actions[\"ADD\"].remove(action_reversed)\n            return 1\n        elif action in self.possible_actions[\"REMOVE\"]:\n            self.graph.remove_edge(*action)\n            self.possible_actions[\"REMOVE\"].remove(action)\n            return 1\n        elif action_reversed in self.possible_actions[\"REMOVE\"]:\n            self.graph.remove_edge(*action_reversed)\n            self.possible_actions[\"REMOVE\"].remove(action_reversed)\n            return 1\n        return 0\n\n    def act(self, action: int) -> Tuple[nx.Graph, bool]:\n        \"\"\"\n        Function that is similar to the `step()` function but we do not compute\n        the metrics and rewards.\n        Indeed this function is used in the evaluation phase.\n\n        Parameters\n        ----------\n        action : int\n            Integer representing a node in the graph, it will be the destination\n            node of the rewiring action (out source node is always the target node).\n\n        Returns\n        -------\n        self.graph : nx.Graph\n            Graph state after the action\n        self.stop_episode : bool\n            If the budget for the graph rewiring is exhausted, or the target\n            node does not belong to the community anymore, the episode is finished\n        \"\"\"\n        # ° ---- ACTION ---- ° #\n        # Take action, add/remove the edge between target node and the model output\n        budget_consumed = self.apply_action(action)\n        if budget_consumed == -1:\n            # ° ---- COMMUNITY DETECTION ---- ° #\n            # Compute the community structure of the graph after the action\n            self.new_community_structure = self.detection.compute_community(self.graph)\n            # Check if the target node still belongs to the community\n            new_community_target = next(\n                (\n                    c\n                    for c in self.new_community_structure.communities\n                    if self.node_target in c\n                ),\n                None,\n            )\n            # ° ---- COMMUNITY SIMILARITY ---- ° #\n            # Remove target node from the communities, but first copy the lists\n            # to avoid modifying them\n            community_target_copy = self.community_target.copy()\n            new_community_target.remove(self.node_target)\n            community_target_copy.remove(self.node_target)\n            # Compute the similarity between the new communities\n            community_similarity = self.community_similarity(\n                new_community_target,\n                community_target_copy,\n            )\n            # Delete the copies\n            del community_target_copy\n            # ° ---------- REWARD ---------- ° #\n            if community_similarity <= self.tau:\n                self.stop_episode = True\n\n        # ° ---- BUDGET ---- ° #\n        # Compute used budget\n        self.used_edge_budget += budget_consumed\n        # If the budget for the graph rewiring is exhausted, stop the episode\n        if self.edge_budget - self.used_edge_budget < 1:\n            self.stop_episode = True\n\n        return self.graph, self.stop_episode\n\n    ############################################################################\n    #                       SETTERS FUNCTIONS                                  #\n    ############################################################################\n    def set_graph(self, graph_path: str) -> None:\n        \"\"\"Set the graph of the environment\"\"\"\n        # Load the graph from the dataset folder\n        if graph_path is None:\n            # Generate a synthetic graph\n            graph, graph_path = Utils.generate_lfr_benchmark_graph()\n        else:\n            graph = Utils.import_mtx_graph(graph_path)\n\n        graph = nx.convert_node_labels_to_integers(\n            graph, first_label=0, ordering=\"sorted\", label_attribute=\"node_type\"\n        )\n\n        self.env_name = graph_path.split(\"/\")[-1].split(\".\")[0]\n        self.graph = self.set_node_features(graph)\n\n        # Save the original graph to restart the rewiring process at each episode\n        self.original_graph = self.graph.copy()\n        # Save the graph state before the action, used to compute the metrics\n        self.old_graph = None\n        # Get the Number of connected components\n        self.n_connected_components = nx.number_connected_components(self.graph)\n\n    def set_node_features(self, graph) -> None:\n        \"\"\"Set the node features of the graph, using Node2Vec\"\"\"\n        print(\"*\" * 20, \"Environment Information\", \"*\" * 20)\n        print(\"* Graph Name:\", self.env_name)\n        print(\"*\", graph)\n        if HyperParams.RANDOM_NODE2VEC.value:\n            for node in graph.nodes():\n                graph.nodes[node][\"x\"] = torch.rand(HyperParams.EMBEDDING_DIM.value)\n        else:\n            print(\"* * Compute Node Embedding using Node2Vec for nodes features\")\n            print(\"* * ...\")\n            # Build node features using Node2Vec, set the embedding dimension to 128.\n            self.embedding_model = Node2Vec(\n                walk_number=HyperParams.WALK_NUMBER.value,\n                walk_length=HyperParams.WALK_LENGTH.value,\n                dimensions=HyperParams.EMBEDDING_DIM.value,\n            )\n            self.embedding_model.fit(graph)\n            print(\"* * End Embedding Computation\")\n            self.embedding = self.embedding_model.get_embedding()\n            # Add the embedding to the graph\n            for node in graph.nodes():\n                graph.nodes[node][\"x\"] = torch.tensor(self.embedding[node])\n\n        for edge in graph.edges():\n            if \"weight\" not in graph.edges[edge]:\n                # Add weight to the edges\n                graph.edges[edge][\"weight\"] = 1\n        return graph\n\n    def set_similarity_funtions(\n        self, community_similarity_function: str, graph_similarity_function: str\n    ) -> None:\n        \"\"\"\n        Set the similarity functions to use to compare the communities and\n        the graphs\n        \"\"\"\n        # Select the similarity function to use to compare the communities\n        self.community_similarity = CommunitySimilarity(\n            community_similarity_function\n        ).select_similarity_function()\n        self.graph_similarity = GraphSimilarity(\n            graph_similarity_function\n        ).select_similarity_function()\n\n    def set_communities(self, community_detection_algorithm) -> None:\n        \"\"\"\n        Set the community detection algorithm to use, and compute the community\n        structure of the graph before the deception actions.\n        \"\"\"\n        self.detection_alg = community_detection_algorithm\n        # Community Algorithms objects\n        self.detection = CommunityDetectionAlgorithm(community_detection_algorithm)\n        # Metrics\n        self.old_penalty_value = 0\n        # Compute the community structure of the graph, before the action,\n        # i.e. before the deception\n        self.original_community_structure = self.detection.compute_community(self.graph)\n        # ! It is a NodeClustering object\n        self.old_community_structure = self.original_community_structure\n\n        # Compute probability distribution of the number of nodes in the communities\n        communities = copy.deepcopy(self.original_community_structure.communities)\n        self.sorted_communities = sorted(communities, key=len)\n        # Get the number of nodes in each community\n        n_nodes = [len(community) for community in self.sorted_communities]\n        # Compute the probability distribution\n        self.prob_dist = [n_node / sum(n_nodes) for n_node in n_nodes]\n        for i, community in enumerate(self.sorted_communities):\n            if len(community) <= 1:\n                self.sorted_communities.pop(i)\n                self.prob_dist.pop(i)\n        assert (\n            len(self.sorted_communities) > 0\n        ), \"No communities with more than one node\"\n\n    def set_preferred_community_size(self, preferred_community_size: int) -> None:\n        \"\"\"\n        Set the preferred community size, to extract the community with the\n        right dimension, i.e. the community with the number of nodes closest\n        to the preferred size.\n\n        Parameters\n        ----------\n        preferred_community_size :\n            Percentage of the maximum community size\n        \"\"\"\n        self.preferred_community_size = preferred_community_size\n\n    def set_rewiring_budget(self) -> None:\n        \"\"\"Set the rewiring budget for the graph, and the valid actions\"\"\"\n        # Compute the action budget for the graph\n        # TEST, use directly the beta parameter\n        self.edge_budget = self.beta\n        # self.edge_budget = self.get_edge_budget()\n        # Amount of budget used\n        self.used_edge_budget = 0\n        # Max Rewiring Steps during an episode, set a limit to avoid infinite\n        # episodes in case the agent does not find the target node\n        self.max_steps = (\n            self.edge_budget * HyperParams.MAX_STEPS_MUL.value\n        )  # self.graph.number_of_edges()\n        # Whether the budget for the graph rewiring is exhausted, or the target\n        # node does not belong to the community anymore\n        self.stop_episode = False\n        self.rewards = 0\n        # Reward of the previous step\n        self.old_rewards = 0\n        # Compute the set of possible actions\n        self.possible_actions = self.get_possible_actions()\n        # Length of the list of possible actions to add\n        self.len_add_actions = len(self.possible_actions[\"ADD\"])\n\n    ############################################################################\n    #                       GETTERS FUNCTIONS                                  #\n    ############################################################################\n\n    def get_edge_budget(self) -> int:\n        \"\"\"\n        Computes the edge budget for each graph\n\n        Returns\n        -------\n        int\n            Edge budgets of the graph\n        \"\"\"\n        # TEST: Three different ways to compute the edge budget\n\n        # 1. Mean degree of the graph times the parameter beta\n        return int(\n            self.graph.number_of_edges() / self.graph.number_of_nodes() * self.beta\n        )\n\n        # 2. Percentage of edges of the whole graph\n        # return int(math.ceil((self.graph.number_of_edges() * self.beta / 100)))\n\n        # 3. Percentage of edges of the whole graph divided by the number of nodes in the community\n        # return int(math.ceil((self.graph.number_of_edges() * self.beta / 100) / len(self.community_target)))\n\n    def get_penalty(self) -> float:\n        \"\"\"\n        Compute the metrics and return the penalty to subtract from the reward\n\n        Returns\n        -------\n        penalty: float\n            Penalty to subtract from the reward\n        \"\"\"\n        # ° ---- COMMUNITY DISTANCE ---- ° #\n        community_distance = self.new_community_structure.normalized_mutual_information(\n            self.old_community_structure\n        ).score\n        # In NMI 1 means that the two community structures are identical,\n        # 0 means that they are completely different\n        # We want to maximize the NMI, so we subtract it from 1\n        community_distance = 1 - community_distance\n        # ° ---- GRAPH DISTANCE ---- ° #\n        graph_distance = self.graph_similarity(self.graph, self.old_graph)\n        # ° ---- PENALTY ---- ° #\n        assert (\n            self.alpha_metric is not None\n        ), \"Alpha metric is None, must be set in grid search\"\n        penalty = (\n            self.alpha_metric * community_distance\n            + (1 - self.alpha_metric) * graph_distance\n        )\n        # Subtract the metric value of the previous step\n        penalty -= self.old_penalty_value\n        # Update with the new values\n        self.old_penalty_value = penalty\n        return penalty\n\n    def get_reward(self) -> Tuple[float, bool]:\n        \"\"\"\n        Computes the reward for the agent, it is a 0-1 value function, if the\n        target node still belongs to the community, the reward is 0 minus the\n        penalty, otherwise the reward is 1 minus the penalty.\n\n        As new community target after the action, we consider the community\n        that contains the target node, if this community satisfies the deception\n        constraint, the episode is finished, otherwise not.\n\n        Returns\n        -------\n        reward : float\n            Reward of the agent\n        done : bool\n            Whether the episode is finished, if the target node does not belong\n            to the community anymore, the episode is finished\n        \"\"\"\n        assert (\n            self.lambda_metric is not None\n        ), \"Lambda metric is None, must be set in grid search\"\n        new_community_target = next(\n            (\n                c\n                for c in self.new_community_structure.communities\n                if self.node_target in c\n            ),\n            None,\n        )\n        assert new_community_target is not None, \"New community target is None\"\n        # ° ---------- PENALTY ---------- ° #\n        # Compute the metric to subtract from the reward\n        penalty = self.get_penalty()\n        # If the target node does not belong to the community anymore,\n        # the episode is finished\n        if len(new_community_target) == 1:\n            reward = 1 - (self.lambda_metric * penalty)\n            return reward, True\n        # ° ---- COMMUNITY SIMILARITY ---- ° #\n        # Remove target node from the communities, but first copy the lists\n        # to avoid modifying them\n        new_community_target_copy = new_community_target.copy()\n        new_community_target_copy.remove(self.node_target)\n        community_target_copy = self.community_target.copy()\n        community_target_copy.remove(self.node_target)\n        # Compute the similarity between the new communities\n        community_similarity = self.community_similarity(\n            new_community_target_copy,\n            community_target_copy,\n        )\n        # Delete the copies\n        del new_community_target_copy, community_target_copy\n        # ° ---------- REWARD ---------- ° #\n        if community_similarity <= self.tau:\n            # We have reached the deception constraint, the episode is finished\n            reward = 1 - (self.lambda_metric * penalty)\n            return reward, True\n        reward = 0 - (self.lambda_metric * penalty)\n        return reward, False\n\n    def get_possible_actions(self) -> dict:\n        \"\"\"\n        Returns all the possible actions that can be applied to the graph\n        given a source node (self.node_target). The possible actions are:\n            - Add an edge between the source node and a node outside the community\n            - Remove an edge between the source node and a node inside the community\n\n        Returns\n        -------\n        self.possible_actions : dict\n            Dictionary containing the possible actions that can be applied to\n            the graph. The dictionary has two keys: \"ADD\" and \"REMOVE\", each\n            key has a list of tuples as value, where each tuple is an action.\n        \"\"\"\n        possible_actions = {\"ADD\": set(), \"REMOVE\": set()}\n        # Helper functions to check if a node is in/out-side the community\n\n        def in_community(node):\n            return node in self.community_target\n\n        def out_community(node):\n            return node not in self.community_target\n\n        u = self.node_target\n        for v in self.graph.nodes():\n            if u == v:\n                continue\n            # We can remove an edge iff both nodes are in the community\n            if in_community(u) and in_community(v):\n                if self.graph.has_edge(u, v):\n                    if (v, u) not in possible_actions[\"REMOVE\"]:\n                        possible_actions[\"REMOVE\"].add((u, v))\n            # We can add an edge iff one node is in the community and the other is not\n            elif (in_community(u) and out_community(v)) or (\n                out_community(u) and in_community(v)\n            ):\n                # Check if there is already an edge between the two nodes\n                if not self.graph.has_edge(u, v):\n                    if (v, u) not in possible_actions[\"ADD\"]:\n                        possible_actions[\"ADD\"].add((u, v))\n        return possible_actions\n\n    ############################################################################\n    #                           ENVIRONMENT INFO                               #\n    ############################################################################\n    def print_env_info(self) -> None:\n        \"\"\"Print the environment information\"\"\"\n        print(\"* Community Detection Algorithm:\", self.detection_alg)\n        print(\n            \"* Number of communities found:\",\n            len(self.original_community_structure.communities),\n        )\n        # print(\"* Rewiring Budget:\", self.edge_budget, \"=\", self.beta, \"*\", self.graph.number_of_edges(), \"/ 100\",)\n        print(\n            \"* BETA - Rewiring Budget: (n_edges/n_nodes)*BETA =\",\n            self.graph.number_of_edges(),\n            \"/\",\n            self.graph.number_of_nodes(),\n            \"*\",\n            self.beta,\n            \"=\",\n            int(self.graph.number_of_edges() / self.graph.number_of_nodes())\n            * self.beta,\n        )\n        print(\"* TAU - Weight of the Deception Constraint:\", self.tau)\n        print(\"*\", \"-\" * 58, \"\\n\")\n","metadata":{"id":"iQDrQKvy4qN2","execution":{"iopub.status.busy":"2023-12-01T07:17:32.288160Z","iopub.execute_input":"2023-12-01T07:17:32.288655Z","iopub.status.idle":"2023-12-01T07:17:32.386667Z","shell.execute_reply.started":"2023-12-01T07:17:32.288619Z","shell.execute_reply":"2023-12-01T07:17:32.385103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Agent","metadata":{"id":"vAdiThYJ4qN3"}},{"cell_type":"code","source":"\nclass Agent:\n    def __init__(\n            self,\n            env: GraphEnvironment,\n            state_dim: int = HyperParams.EMBEDDING_DIM.value,\n            hidden_size_1: int = HyperParams.HIDDEN_SIZE_1.value,\n            hidden_size_2: int = HyperParams.HIDDEN_SIZE_2.value,\n            lr: List[float] = HyperParams.LR.value,\n            gamma: List[float] = HyperParams.GAMMA.value,\n            lambda_metrics: List[float] = HyperParams.LAMBDA.value,\n            alpha_metrics: List[float] = HyperParams.ALPHA.value,\n            epsilon_probs: float = HyperParams.EPSILON.value,\n            weight_decay: float = HyperParams.WEIGHT_DECAY.value,\n            dropout: float = HyperParams.DROPOUT.value,\n            eps: float = HyperParams.EPS_CLIP.value,\n            best_reward: float = HyperParams.BEST_REWARD.value)-> None:\n        \"\"\"\n        Initialize the agent.\n\n        Parameters\n        ----------\n        env : GraphEnvironment\n            Environment to train the agent on\n        state_dim : int\n            Dimensions of the state, i.e. length of the feature vector\n        hidden_size_1 : int\n            First A2C hidden layer size\n        hidden_size_2 : int\n            Second A2C hidden layer size\n        action_dim : int\n            Dimensions of the action (it is set to 1, to return a tensor N*1)\n        lr : List[float]\n            List of Learning rate, each element of the list is a learning rate\n        gamma : List[float]\n            List of gamma parameter, each element of the list is a gamma\n        lambda_metrics : List[float]\n            List of lambda parameter, each element of the list is a lambda used\n            to balance the reward and the penalty\n        alpha_metrics : List[float]\n            List of alpha parameter, each element of the list is a alpha used\n            to balance the two penalties\n        eps : List[float]\n            Value for clipping the loss function, each element of the list is a\n            clipping value\n        best_reward : float, optional\n            Best reward, by default 0.8\n        \"\"\"\n        # ° ----- Environment ----- ° #\n        self.env = env\n\n        # ° ----- A2C ----- ° #\n        self.state_dim = state_dim # self.env.graph.number_of_nodes()\n        self.hidden_size_1 = hidden_size_1\n        self.hidden_size_2 = hidden_size_2\n        self.action_dim = self.env.graph.number_of_nodes()\n        self.dropout = dropout\n        self.policy = ActorCritic(\n            state_dim=self.state_dim,\n            hidden_size_1=self.hidden_size_1,\n            hidden_size_2=self.hidden_size_2,\n            action_dim=self.action_dim,\n            dropout=self.dropout,\n        )\n        # Set device\n        self.device = torch.device(\n            'cuda:0' if torch.cuda.is_available() else 'cpu')\n        # Move model to device\n        self.policy.to(self.device)\n\n        # ° ----- Hyperparameters ----- ° #\n        # A2C hyperparameters\n        self.lr_list = lr\n        self.gamma_list = gamma\n        self.eps = eps\n        self.best_reward = best_reward\n        self.epsilon_probs = epsilon_probs\n        # Environment hyperparameters\n        self.lambda_metrics = lambda_metrics\n        self.alpha_metrics = alpha_metrics\n        self.weight_decay = weight_decay\n        # Hyperparameters to be set during grid search\n        self.lr = None\n        self.gamma = None\n        self.alpha_metric = None\n        self.epsilon_prob = None\n        self.optimizers = dict()\n\n        # ° ----- Training ----- ° #\n        # State, nx.Graph\n        self.obs = None\n        # Cumulative reward of the episode\n        self.episode_reward = 0\n        self.episode_entropy = 0\n        self.entropy_coeff = 0.02\n        # Boolean variable to check if the episode is ended\n        self.done = False\n        # Boolean variable to check if the goal is reached\n        self.goal = False\n        # Number of steps in the episode\n        self.step = 0\n        # Tuple to store the values for each action\n        self.SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n        self.saved_actions = []\n        self.rewards = []\n        # List of rewards for one episode\n        self.episode_rewards = []\n        # Initialize lists for logging, it contains: avg_reward, avg_steps per episode\n        self.log_dict = HyperParams.LOG_DICT.value\n        # Print agent info\n        self.print_agent_info()\n\n        # ° ----- Evaluation ----- ° #\n        # List of actions performed during the evaluation\n        self.action_list = {\"ADD\": [], \"REMOVE\": []}\n\n    ############################################################################\n    #                       PRE-TRAINING/TESTING                               #\n    ############################################################################\n    def reset_hyperparams(\n            self,\n            lr: float,\n            gamma: float,\n            lambda_metric: float,\n            alpha_metric: float,\n            epsilon_prob: float,\n            test: bool = False) -> None:\n        \"\"\"\n        Reset hyperparameters\n        \n        Parameters\n        ----------\n        lr : float\n            Learning rate\n        gamma : float\n            Discount factor\n        lambda_metric : float\n            Lambda parameter used to balance the reward and the penalty\n        alpha_metric : float\n            Alpha parameter used to balance the two penalties\n        epsilon_prob : float\n            Probability of changing the target node and the target community\n        test : bool, optional\n            Print hyperparameters during training, by default False\n        \"\"\"\n        # Set A2C hyperparameters\n        self.lr = lr\n        self.gamma = gamma\n        if epsilon_prob < 0 or epsilon_prob > 100:\n            raise ValueError(\"Epsilon must be between 0 and 100\")\n        self.epsilon_prob = epsilon_prob\n        # Set environment hyperparameters\n        self.env.lambda_metric = lambda_metric\n        self.env.alpha_metric = alpha_metric\n        # Print hyperparameters if we are not testing\n        if not test:\n            self.print_hyperparams()\n        # Clear logs, except for the training episodes\n        for key in self.log_dict.keys():\n            if key != 'train_episodes':\n                self.log_dict[key] = list()\n        # Clear action list\n        self.saved_actions = []\n        self.rewards = []\n        self.episode_rewards = []\n        # Clear state\n        self.obs = None\n        self.episode_reward = 0\n        self.episode_entropy = 0\n        self.best_reward = HyperParams.BEST_REWARD.value\n        self.done = False\n        self.goal = False\n        self.step = 0\n        self.optimizers = dict()\n        \n        # Reset the weights of the policy network\n        del self.policy\n        self.policy = ActorCritic(\n            state_dim=self.state_dim,\n            hidden_size_1=self.hidden_size_1,\n            hidden_size_2=self.hidden_size_2,\n            action_dim=self.action_dim,\n            dropout=self.dropout,\n        )\n        # Set device\n        self.policy.to(self.device)\n\n    def configure_optimizers(self) -> None:\n        \"\"\"\n        Configure optimizers\n        \n        Returns\n        -------\n        optimizers : dict\n            Dictionary of optimizers\n        \"\"\"\n        actor_params = list(self.policy.actor.parameters())\n        critic_params = list(self.policy.critic.parameters())\n        self.optimizers['a_optimizer'] = torch.optim.Adam(\n            actor_params, lr=self.lr, weight_decay=self.weight_decay)\n        self.optimizers['c_optimizer'] = torch.optim.Adam(\n            critic_params, lr=self.lr, weight_decay=self.weight_decay)\n\n    ############################################################################\n    #                            GRID SEARCH                                   #\n    ############################################################################\n    def grid_search(self) -> None:\n        \"\"\"Perform grid search on the hyperparameters\"\"\"\n        # Iterate over all the possible combinations of hyperparameters\n        for lr, gamma, lambda_metric, alpha_metric, epsilon_prob in product(\n                self.lr_list, \n                self.gamma_list, \n                self.lambda_metrics,\n                self.alpha_metrics, \n                self.epsilon_probs):\n                        # Change Hyperparameters\n                        self.reset_hyperparams(\n                            lr, gamma, lambda_metric, alpha_metric, epsilon_prob)\n                        # Configure optimizers with the current learning rate\n                        self.configure_optimizers()\n                        # Training\n                        log = self.training()\n                        # Save results in correct folder\n                        self.save_plots(log, self.get_path())\n                        # Free memory\n                        gc.collect()\n\n    ############################################################################\n    #                               TRAINING                                   #\n    ############################################################################\n    def training(self) -> dict:\n        \"\"\"\n        Train the agent on the environment, change the target node every 10\n        episodes and the target community every 100 episodes. The episode ends\n        when the target node is isolated from the target community, or when the\n        maximum number of steps is reached.\n            \n        Returns\n        -------\n        log_dict : dict\n            Dictionary containing the training logs\n        \"\"\"\n        episode = self.log_dict['train_episodes']\n        epochs = trange(episode)  # epoch iterator\n        self.policy.train()  # set model in train mode\n        mean_avg_reward = 0\n        mean_avg_reward_steps = 0\n        for i_episode in epochs:\n            \n            # With probability epsilon, change the community target and the\n            # node target\n            if random.randint(0, 100) < self.epsilon_prob:\n                self.env.change_target_community()\n            \n            # Print node_target and community_target\n            # print(\"* Node target:\", self.env.node_target)\n            # print(\"* Community target:\", self.env.community_target)\n            # Reset environment, original graph, and new set of possible actions\n            self.obs = self.env.reset()\n            self.episode_reward = 0\n            self.episode_entropy = 0\n            self.done = False\n            self.goal = False\n            self.episode_rewards = []\n            self.step = 0\n            \n            # Rewiring the graph until the target node is isolated from the\n            # target community\n            while not self.done and self.step < self.env.max_steps:\n                self.rewiring()\n                \n            # perform on-policy backpropagation\n            self.a_loss, self.v_loss = self.training_step()\n            # Checkpoint best performing model\n            if self.episode_reward / self.step >= self.best_reward:\n                self.save_checkpoint()\n                self.best_reward = self.episode_reward\n\n            # ° Log\n            # Get the list of reward of the last self.step steps\n            rewards = self.episode_rewards[-self.step:]\n            # If the goal is reached, multiply the last reward by 10\n            if self.goal:\n                rewards[-1] *= 10\n            self.log_dict['train_reward_list'].append(rewards)\n            self.log_dict['train_reward_mul'].append(sum(rewards)/len(rewards))\n\n            self.log_dict['train_reward'].append(self.episode_reward)\n            self.log_dict['train_steps'].append(self.step)\n            self.log_dict['train_avg_reward'].append(\n                self.episode_reward/self.step)\n            self.log_dict['a_loss'].append(self.a_loss)\n            self.log_dict['v_loss'].append(self.v_loss)\n\n            # Send current statistics to screen\n            epochs.set_description(\n                f\"* Episode {i_episode+1} \" +\n                f\"| Mul Reward: {sum(rewards)/len(rewards):.2f}\"\n                f\"| Avg Reward: {self.episode_reward/self.step:.2f} \" +\n                f\"| Steps: {self.step} \" +\n                f\"| Actor Loss: {self.a_loss:.2f} \" +\n                f\"| Critic Loss: {self.v_loss:.2f}\")\n            mean_avg_reward += self.episode_reward/self.step\n            mean_avg_reward_steps += 1\n            del rewards\n        return self.log_dict\n\n    def rewiring(self, test=False) -> None:\n        \"\"\"\n        Rewiring step, select action and take step in environment.\n        \n        Parameters\n        ----------\n        test : bool, optional\n            If True, print rewiring action, by default False\n        \"\"\"\n        # Select action: return a list of the probabilities of each action\n        action_rl, entropy = self.select_action(self.obs)\n        torch.cuda.empty_cache()\n        # Save rewiring action if we are testing\n        if test:\n            edge = (self.env.node_target, action_rl)\n            if edge in self.env.possible_actions[\"ADD\"]:\n                if not self.env.graph.has_edge(*edge):\n                    # print(\"* ADD\", edge)\n                    self.action_list[\"ADD\"].append(edge)\n            elif edge in self.env.possible_actions[\"REMOVE\"]:\n                if self.env.graph.has_edge(*edge):\n                    # print(\"* REMOVE\", edge)\n                    self.action_list[\"REMOVE\"].append(edge)\n            \n            # Take the action in the environment without computing the reward\n            self.obs, self.done = self.env.act(action_rl)\n            return\n        \n        # Take action in environment, compute reward and check if the goal is\n        # reached\n        self.obs, reward, self.done, self.goal = self.env.step(action_rl)\n        # Update episode reward and entropy\n        self.episode_entropy += entropy\n        self.episode_reward += reward\n        # Store the transition in memory, used for the training step\n        self.rewards.append(reward)\n        # Used for logging\n        self.episode_rewards.append(reward)\n        self.step += 1\n\n    def select_action(self, state: nx.Graph) -> int:\n        \"\"\"\n        Select action, given a state, using the policy network.\n        \n        Parameters\n        ----------\n        state : nx.Graph\n            Current state of the environment\n        \n        Returns\n        -------\n        action: int\n            Integer representing a node in the graph, it will be the destination\n            node of the rewiring action\n        \"\"\"\n        concentration, value = self.policy(state)\n        dist = torch.distributions.Categorical(concentration)\n        entropy = dist.entropy().mean()\n        action = dist.sample()\n        self.saved_actions.append(\n            self.SavedAction(dist.log_prob(action), value))\n        return int(action.item()), entropy\n\n    def training_step(self) -> Tuple[float, float]:\n        \"\"\"\n        Perform a single training step of the A2C algorithm, which involves\n        computing the actor and critic losses, taking gradient steps, and \n        resetting the rewards and action buffer.\n        \n        Returns\n        -------\n        mean_a_loss : float\n            Mean actor loss\n        mean_v_loss : float\n            Mean critic loss\n        \"\"\"\n        R = 0\n        saved_actions = self.saved_actions\n        policy_losses = []  # list to save actor (policy) loss\n        value_losses = []  # list to save critic (value) loss\n        returns = []  # list to save the true values\n        # Compute the true value using rewards returned from the environment\n        for r in self.rewards[::-1]:\n            # calculate the discounted value\n            R = r + self.gamma * R\n            # insert to the beginning of the list\n            returns.insert(0, R)\n        # Normalize returns by subtracting mean and dividing by standard deviation\n        # NOTE: May cause NaN problem\n        if len(returns) > 1:\n            returns = torch.tensor(returns)\n            returns = (returns - returns.mean()) / (returns.std() + self.eps)\n        else:\n            returns = torch.tensor(returns)\n        \n        # Computing losses\n        for (log_prob, value), R in zip(saved_actions, returns):\n            # Difference between true value and estimated value from critic\n            advantage = R - value.item()\n            # calculate actor (policy) loss\n            policy_losses.append(-log_prob * advantage) # Old\n            # calculate critic (value) loss using L1 smooth loss\n            value_losses.append(F.smooth_l1_loss(\n                value, torch.tensor([R]).to(self.device)))\n\n        # take gradient steps\n        self.optimizers['a_optimizer'].zero_grad()\n        a_loss = torch.stack(policy_losses).sum() \n        a_loss.backward()\n        self.optimizers['a_optimizer'].step()\n        \n        self.optimizers['c_optimizer'].zero_grad()\n        v_loss = torch.stack(value_losses).sum()\n        v_loss.backward()\n        self.optimizers['c_optimizer'].step()\n        \n        # Compute mean losses\n        mean_a_loss = torch.stack(policy_losses).mean().item()\n        mean_v_loss = torch.stack(value_losses).mean().item()\n        # reset rewards and action buffer\n        del self.rewards[:]\n        del self.saved_actions[:]\n        return mean_a_loss, mean_v_loss\n\n    ############################################################################\n    #                               TEST                                       #\n    ############################################################################\n    def test(\n            self,\n            lr: float,\n            gamma: float,\n            lambda_metric: float,\n            alpha_metric: float,\n            epsilon_prob: float,\n            model_path: str,\n            graph_reset=True) -> nx.Graph:\n        \"\"\"Hide a given node from a given community\"\"\"\n        # Set hyperparameters to select the correct folder\n        self.reset_hyperparams(lr, gamma, lambda_metric, alpha_metric, epsilon_prob, True)\n        # Load best performing model\n        self.load_checkpoint(path=model_path)\n        # Set model in evaluation mode\n        self.policy.eval()\n        self.obs = self.env.reset(graph_reset)\n        # Rewiring the graph until the target node is isolated from the\n        # target community\n        while not self.done and self.step < self.env.max_steps:\n            self.rewiring(test=True)\n        return self.obs\n\n    ############################################################################\n    #                            CHECKPOINTING                                 #\n    ############################################################################\n    def get_path(self) -> str:\n        \"\"\"\n        Return the path of the folder where to save the plots and the logs\n        \n        Returns\n        -------\n        file_path : str\n            Path to the correct folder\n        \"\"\"\n        file_path = FilePaths.LOG_DIR.value + \\\n            f\"{self.env.env_name}/{self.env.detection_alg}/\" +\\\n            f\"eps-{self.epsilon_prob}/\" +\\\n            f\"lr-{self.lr}/gamma-{self.gamma}/\" +\\\n            f\"lambda-{self.env.lambda_metric}/alpha-{self.env.alpha_metric}\"\n        return file_path\n\n    def save_plots(self, log: dict, file_path: str) -> None:\n        \"\"\"\n        Save training plots and logs\n\n        Parameters\n        ----------\n        log : dict\n            Dict containing the training logs\n        file_path : str\n            Path to the directory where to save the plots and the logs\n        \"\"\"\n        Utils.check_dir(file_path)\n        self.log(log)\n        Utils.plot_training(\n            log,\n            self.env.env_name,\n            self.env.detection_alg,\n            file_path)\n\n    def save_checkpoint(self):\n        \"\"\"Save checkpoint\"\"\"\n        log_dir = self.get_path()\n        # Check if the directory exists, otherwise create it\n        Utils.check_dir(log_dir)\n        checkpoint = dict()\n        checkpoint['model'] = self.policy.state_dict()\n        for key, value in self.optimizers.items():\n            checkpoint[key] = value.state_dict()\n        path = f'{log_dir}/model.pth'\n        torch.save(checkpoint, path)\n\n    def load_checkpoint(self, path=None):\n        \"\"\"Load checkpoint\"\"\"\n        if path is None:\n            log_dir = self.get_path()\n            path = f'{log_dir}/model.pth'\n        \n        checkpoint = torch.load(path, map_location=self.device)\n        self.policy.load_state_dict(checkpoint['model'])\n        for key, _ in self.optimizers.items():\n            self.optimizers[key].load_state_dict(checkpoint[key])\n\n    def log(self, log_dict: dict):\n        \"\"\"Log data\n        \n        Parameters\n        ----------\n        log_dict : dict\n            Dictionary containing the data to be logged\n        \"\"\"\n        log_dir = self.get_path()\n        Utils.check_dir(log_dir)\n        file_name = f'{log_dir}/training_results.json'\n        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n            json.dump(log_dict, f, indent=4)\n\n    ############################################################################\n    #                   AGENT INFO AND PRINTING                                #\n    ############################################################################\n    def print_agent_info(self):\n        # Print model architecture\n        print(\"*\", \"-\"*18, \" Model Architecture \", \"-\"*18)\n        print(\"* Dropout:                   \", self.dropout)\n        print(\"* Weight Decay:              \", self.weight_decay)\n        print(\"* Features vector size:      \", self.state_dim)\n        print(\"* A2C Hidden layer 1 size:   \", self.hidden_size_1)\n        print(\"* A2C Hidden layer 2 size:   \", self.hidden_size_2)\n        print(\"* Actor Action dimension:    \", self.action_dim)\n        print(\"*\", \"-\"*58, \"\\n\")\n        # Print Hyperparameters List\n        print(\"*\", \"-\"*18, \"Hyperparameters List\", \"-\"*18)\n        print(\"* LR       - Learning Rate:      \", self.lr_list)\n        print(\"* Episilon - Probability:        \", self.epsilon_probs)\n        print(\"* Gamma    - Discount Factor:    \", self.gamma_list)\n        print(\"* Lambda   - Penalty Multiplier: \", self.lambda_metrics)\n        print(\"* Alpha    - Similarity Balancer:\", self.alpha_metrics)\n        print(\"*\", \"-\"*58, \"\\n\")\n\n    def print_hyperparams(self):\n        print(\"*\", \"-\"*18, \"Model Hyperparameters\", \"-\"*18)\n        print(\"* LR       - Learning Rate:      \", self.lr)\n        print(\"* Episilon - Probability:        \", self.epsilon_prob)\n        print(\"* Gamma    - Discount Factor:    \", self.gamma)\n        print(\"* Lambda   - Penalty Multiplier: \", self.env.lambda_metric)\n        print(\"* Alpha    - Similarity Balancer:\", self.env.alpha_metric)\n        # print(\"* Value for clipping the loss function: \", self.eps)\n","metadata":{"id":"KUntGR5MGjVD","execution":{"iopub.status.busy":"2023-12-01T07:17:32.407393Z","iopub.execute_input":"2023-12-01T07:17:32.407838Z","iopub.status.idle":"2023-12-01T07:17:32.492544Z","shell.execute_reply.started":"2023-12-01T07:17:32.407806Z","shell.execute_reply":"2023-12-01T07:17:32.491049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### A2C","metadata":{"id":"1S7ubGoY4qN4"}},{"cell_type":"markdown","source":"#### Actor","metadata":{"id":"SfScUOtU4qN4"}},{"cell_type":"code","source":"class ActorNetwork(nn.Module):\n    \"\"\"Actor Network\"\"\"\n\n    def __init__(\n            self,\n            state_dim: int,\n            hidden_size_1: int,\n            hidden_size_2: int,\n            action_dim: int,\n            dropout: float):\n        super(ActorNetwork, self).__init__()\n\n        # self.conv1 = GCNConv(state_dim, hidden_size_1)\n        self.conv1 = GCNConv(state_dim, state_dim)\n\n        # self.lin1 = nn.Linear(hidden_size_1, hidden_size_1)\n        self.lin1 = nn.Linear(state_dim, hidden_size_1)\n\n        self.lin2 = nn.Linear(hidden_size_1, hidden_size_2)\n        self.lin3 = nn.Linear(hidden_size_2, 1)\n\n        # self.relu = nn.LeakyReLU()\n        self.relu = nn.ReLU()\n        # self.tanh = nn.Tanh()\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, data: Data) -> torch.Tensor:\n        out = F.relu(self.conv1(data.x, data.edge_index))\n        x = out + data.x\n        x = F.relu(self.lin1(x))\n        x = self.dropout(x)\n        x = F.relu(self.lin2(x))\n        x = self.dropout(x)\n        x = self.lin3(x)\n        return x","metadata":{"id":"HV4Ef1504qN4","execution":{"iopub.status.busy":"2023-12-01T07:17:32.494685Z","iopub.execute_input":"2023-12-01T07:17:32.495018Z","iopub.status.idle":"2023-12-01T07:17:32.510868Z","shell.execute_reply.started":"2023-12-01T07:17:32.494991Z","shell.execute_reply":"2023-12-01T07:17:32.509374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Critic","metadata":{"id":"4L57IBdh4qN4"}},{"cell_type":"code","source":"class CriticNetwork(nn.Module):\n    def __init__(\n            self,\n            state_dim: int,\n            hidden_size_1: int,\n            hidden_size_2: int,\n            dropout: float):\n        super(CriticNetwork, self).__init__()\n\n        # self.conv1 = GCNConv(state_dim, hidden_size_1)\n        self.conv1 = GCNConv(state_dim, state_dim)\n\n        # self.lin1 = nn.Linear(hidden_size_1, hidden_size_1)\n        self.lin1 = nn.Linear(state_dim, hidden_size_1)\n\n        self.lin2 = nn.Linear(hidden_size_1, hidden_size_2)\n        self.lin3 = nn.Linear(hidden_size_2, 1)\n\n        # self.relu = nn.LeakyReLU()\n        self.relu = nn.ReLU()\n        # self.relu = F.relu\n        # self.tanh = nn.Tanh()\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, data: Data) -> torch.Tensor:\n        out = F.relu(self.conv1(data.x, data.edge_index))\n        x = out + data.x\n        x = torch.sum(x, dim=0)\n        # x = torch.sum(out, dim=0)\n        x = self.relu(self.lin1(x))\n        x = self.dropout(x)\n        x = self.relu(self.lin2(x))\n        x = self.dropout(x)\n        x = self.lin3(x)\n        return x","metadata":{"id":"jRxY8xcL4qN4","execution":{"iopub.status.busy":"2023-12-01T07:17:32.512296Z","iopub.execute_input":"2023-12-01T07:17:32.512658Z","iopub.status.idle":"2023-12-01T07:17:32.529104Z","shell.execute_reply.started":"2023-12-01T07:17:32.512629Z","shell.execute_reply":"2023-12-01T07:17:32.527597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### A2C","metadata":{"id":"SzgdEPGCKz3p"}},{"cell_type":"code","source":"class ActorCritic(nn.Module):\n    \"\"\"ActorCritic Network\"\"\"\n\n    def __init__(\n            self,\n            state_dim: int,\n            hidden_size_1: int,\n            hidden_size_2: int,\n            action_dim: int,\n            dropout: float):\n        super(ActorCritic, self).__init__()\n        self.actor = ActorNetwork(\n            state_dim=state_dim,\n            hidden_size_1=hidden_size_1,\n            hidden_size_2=hidden_size_2,\n            action_dim=action_dim,\n            dropout=dropout,\n        )\n        self.critic = CriticNetwork(\n            state_dim=state_dim,\n            hidden_size_1=hidden_size_1,\n            hidden_size_2=hidden_size_2,\n            dropout=dropout,\n        )\n        self.device = torch.device(\n            'cuda:0' if torch.cuda.is_available() else 'cpu')\n\n    def forward(self, graph: nx.Graph, jitter=1e-20) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Forward pass, computes action and value\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            Graph state\n        jitter : float, optional\n            Jitter value, by default 1e-20\n\n        Returns\n        -------\n        Tuple[torch.Tensor, torch.Tensor]\n            Tuple of concentration and value\n        \"\"\"\n        # Convert graph to torch_geometric.data.Data\n        state = from_networkx(graph).to(self.device)\n\n        # Actor\n        probs = self.actor(state)\n        # Use softplus to ensure concentration is positive, then add jitter to\n        # ensure numerical stability\n        concentration = F.softplus(probs).reshape(-1) + jitter\n\n        # Critic\n        value = self.critic(state)\n        return concentration, value\n","metadata":{"id":"gCGlW6YNKz3p","execution":{"iopub.status.busy":"2023-12-01T07:17:32.531945Z","iopub.execute_input":"2023-12-01T07:17:32.532399Z","iopub.status.idle":"2023-12-01T07:17:32.545397Z","shell.execute_reply.started":"2023-12-01T07:17:32.532363Z","shell.execute_reply":"2023-12-01T07:17:32.544352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{"id":"RA1YamymHWH7"}},{"cell_type":"markdown","source":"### Node Hiding","metadata":{"id":"YWv9e06m-dky"}},{"cell_type":"code","source":"class NodeHiding:\n    \"\"\"\n    Class to evaluate the performance of the agent on the Node Hiding task, and\n    compare it with the baseline algorithms:\n        - Random Hiding: choose randomly the edges to remove/add\n        - Degree Hiding: choose the edges to remove/add based on the degree\n        - Roam Heuristic: use roam heuristic\n    \"\"\"\n\n    def __init__(\n        self,\n        agent: Agent,\n        model_path: str,\n        lr: float = HyperParams.LR_EVAL.value,\n        gamma: float = HyperParams.GAMMA_EVAL.value,\n        lambda_metric: float = HyperParams.LAMBDA_EVAL.value,\n        alpha_metric: float = HyperParams.ALPHA_EVAL.value,\n        epsilon_prob: float = HyperParams.EPSILON_EVAL.value,\n        eval_steps: int = HyperParams.STEPS_EVAL.value,\n    ) -> None:\n        self.agent = agent\n        self.original_graph = agent.env.original_graph.copy()\n        self.model_path = model_path\n        self.env_name = agent.env.env_name\n        self.detection_alg = agent.env.detection_alg\n        self.community_target = agent.env.community_target\n\n        # Copy the community structure to avoid modifying the original one\n        self.community_structure = copy.deepcopy(agent.env.original_community_structure)\n        self.node_target = agent.env.node_target\n\n        self.lr = lr\n        self.gamma = gamma\n        self.lambda_metric = lambda_metric\n        self.alpha_metric = alpha_metric\n        self.epsilon_prob = epsilon_prob\n        self.eval_steps = eval_steps\n\n        self.beta = None\n        self.tau = None\n        self.edge_budget = None\n        self.max_steps = None\n\n        # HyperParams.ALGS_EVAL.value\n        self.evaluation_algs = [\"Agent\", \"Random\", \"Degree\", \"Roam\"]\n\n    def set_parameters(self, beta: int, tau: float) -> None:\n        \"\"\"Set the environment with the new parameters, for new experiments\n\n        Parameters\n        ----------\n        beta : int\n            Multiplicative factor for the number of edges to remove/add\n        tau : float\n            Constraint on the goal achievement\n        \"\"\"\n        self.beta = beta\n        self.tau = tau\n\n        self.agent.env.beta = beta\n        self.agent.env.tau = tau\n        self.agent.env.set_rewiring_budget()\n\n        self.edge_budget = self.agent.env.edge_budget\n        if self.edge_budget < 1:\n            raise ValueError(\"Edge budget must be greater than 1\")\n        self.max_steps = self.agent.env.max_steps\n\n        # Initialize the log dictionary\n        self.set_log_dict()\n\n        self.path_to_save = (\n            FilePaths.TEST_DIR.value\n            + f\"{self.env_name}/{self.detection_alg}/\"\n            + f\"node_hiding/\"\n            + f\"tau_{self.tau}/\"\n            + f\"beta_{self.beta}/\"\n            + f\"eps_{self.epsilon_prob}/\"\n            + f\"lr_{self.lr}/gamma_{self.gamma}/\"\n            + f\"lambda_{self.lambda_metric}/alpha_{self.alpha_metric}/\"\n        )\n\n    def reset_experiment(self, target_community=True) -> None:\n        \"\"\"\n        Reset the environment and the agent at the beginning of each episode,\n        and change the target community and node\n\n        Parameters\n        ----------\n        target_community : bool, optional\n            If True, change the target community, by default True\n        \"\"\"\n        if target_community:\n            self.agent.env.change_target_community()\n            # Copy the community target to avoid modifying the original one\n            self.community_target = copy.deepcopy(self.agent.env.community_target)\n        else:\n            self.agent.env.change_target_node()\n        self.node_target = self.agent.env.node_target\n\n        # Baseline algorithms\n        self.random_hiding = RandomHiding(\n            env=self.agent.env,\n            steps=self.edge_budget,\n            target_community=self.community_target,\n        )\n        self.degree_hiding = DegreeHiding(\n            env=self.agent.env,\n            steps=self.edge_budget,\n            target_community=self.community_target,\n        )\n        self.roam_hiding = RoamHiding(\n            self.original_graph, self.node_target, self.edge_budget, self.detection_alg\n        )\n\n    ############################################################################\n    #                               EVALUATION                                 #\n    ############################################################################\n    def run_experiment(self):\n        \"\"\"\n        Function to run the evaluation of the agent on the Node Hiding task,\n        and compare it with the baseline algorithms\n        \"\"\"\n        # Start evaluation\n        if HyperParams.COMMUNITY_CHANGE_METHOD.value == 2:\n            preferred_size_list = HyperParams.PREFERRED_COMMUNITY_SIZE.value\n        else:\n            preferred_size_list = [self.agent.env.preferred_community_size]\n        sizes = trange(\n            len(preferred_size_list), desc=\"* * * Community Size\", leave=True\n        )\n        for i in sizes:\n            # Change the community size at each episode\n            self.agent.env.preferred_community_size = preferred_size_list[i]\n            # print(\"* Community Size:\", self.agent.env.preferred_community_size)\n            # Change the target community\n            self.reset_experiment()\n            sizes.set_description(f\"* * * Community Size {len(self.community_target)}\")\n            steps = trange(self.eval_steps, desc=\"Testing Episode\", leave=False)\n            for step in steps:\n                # print(\"* Node Target:\", self.node_target)\n                # print(\"* Community Target Length:\", len(self.community_target))\n                # print(\"* Edge Budget:\", self.edge_budget)\n\n                # Change target node within the community\n                self.reset_experiment(target_community=False)\n\n                # ° ------ Agent Rewiring ------ ° #\n                steps.set_description(\n                    f\"* * * Testing Episode {step+1} | Agent Rewiring\"\n                )\n                self.run_alg(self.run_agent)\n\n                # ° ------   Baselines   ------ ° #\n                # Random Rewiring\n                steps.set_description(\n                    f\"* * * Testing Episode {step+1} | Random Rewiring\"\n                )\n                self.run_alg(self.run_random)\n\n                # Degree Rewiring\n                steps.set_description(\n                    f\"* * * Testing Episode {step+1} | Degree Rewiring\"\n                )\n                self.run_alg(self.run_degree)\n\n                # Roam Rewiring\n                steps.set_description(f\"* * * Testing Episode {step+1} | Roam Rewiring\")\n                self.run_alg(self.run_roam)\n\n        Utils.check_dir(self.path_to_save)\n        Utils.save_test(\n            log=self.log_dict,\n            files_path=self.path_to_save,\n            log_name=\"evaluation_node_hiding\",\n            algs=self.evaluation_algs,\n            metrics=[\"nmi\", \"goal\", \"time\", \"steps\"],\n        )\n\n    # Define a function to run each algorithm\n    def run_alg(self, function: Callable) -> None:\n        \"\"\"\n        Wrapper function to run the evaluation of a generic algorithm\n\n        Parameters\n        ----------\n        function : Callable\n            Algorithm to evaluate\n        \"\"\"\n        start = time.time()\n        alg_name, new_communities, step = function()\n        end = time.time() - start\n\n        # Compute NMI\n        nmi = self.get_nmi(self.community_structure, new_communities)\n\n        # Check if the goal was achieved\n        community_target = self.get_new_community(new_communities)\n        goal = self.check_goal(community_target)\n\n        # Save results in the log dictionary\n        self.save_metrics(alg_name, goal, nmi, end, step)\n\n    ############################################################################\n    #                               AGENT                                      #\n    ############################################################################\n    def run_agent(self) -> Tuple[str, cdlib.NodeClustering, int]:\n        \"\"\"\n        Evaluate the agent on the Node Hiding task\n\n        Returns\n        -------\n        Tuple[str, cdlib.NodeClustering, int]:\n            Algorithm name, Set of new communities, steps\n        \"\"\"\n        new_graph = self.agent.test(\n            lr=self.lr,\n            gamma=self.gamma,\n            lambda_metric=self.lambda_metric,\n            alpha_metric=self.alpha_metric,\n            epsilon_prob=self.epsilon_prob,\n            model_path=self.model_path,\n        )\n\n        # Compute the new community structure\n        self.agent.env.new_community_structure = (\n            self.agent.env.detection.compute_community(new_graph)\n        )\n\n        return (\n            self.evaluation_algs[0],\n            self.agent.env.new_community_structure,\n            self.agent.env.used_edge_budget,\n        )\n\n    ############################################################################\n    #                               BASELINES                                  #\n    ############################################################################\n    def run_random(self) -> Tuple[str, cdlib.NodeClustering, int]:\n        \"\"\"\n        Evaluate the Random Hiding algorithm on the Node Hiding task\n\n        Returns\n        -------\n        Tuple[str, cdlib.NodeClustering, int]:\n            Algorithm name, Set of new communities, steps\n        \"\"\"\n        (\n            rh_graph,\n            rh_communities,\n            steps,\n        ) = self.random_hiding.hide_target_node_from_community()\n        return self.evaluation_algs[1], rh_communities, steps\n\n    def run_degree(self) -> Tuple[str, cdlib.NodeClustering, int]:\n        \"\"\"\n        Evaluate the Degree Hiding algorithm on the Node Hiding task\n\n        Returns\n        -------\n        Tuple[str, cdlib.NodeClustering, int]:\n            Algorithm name, Set of new communities, steps\n        \"\"\"\n        (\n            dh_graph,\n            dh_communities,\n            steps,\n        ) = self.degree_hiding.hide_target_node_from_community()\n        return self.evaluation_algs[2], dh_communities, steps\n\n    def run_roam(self) -> Tuple[str, cdlib.NodeClustering, int]:\n        \"\"\"\n        Evaluate the Roam Hiding algorithm on the Node Hiding task\n\n        Returns\n        -------\n        Tuple[str, cdlib.NodeClustering, int]:\n            Algorithm name, Set of new communities, steps\n        \"\"\"\n        ro_graph, ro_communities = self.roam_hiding.roam_heuristic(self.edge_budget)\n        return self.evaluation_algs[3], ro_communities, self.edge_budget\n\n    ############################################################################\n    #                               UTILS                                      #\n    ############################################################################\n    def get_nmi(\n        self,\n        old_communities: cdlib.NodeClustering,\n        new_communities: cdlib.NodeClustering,\n    ) -> float:\n        \"\"\"\n        Compute the Normalized Mutual Information between the old and the new\n        community structure\n\n        Parameters\n        ----------\n        old_communities : cdlib.NodeClustering\n            Community structure before deception\n        new_communities : cdlib.NodeClustering\n            Community structure after deception\n\n        Returns\n        -------\n        float\n            Normalized Mutual Information between the old and the new community\n        \"\"\"\n        if new_communities is None:\n            # The agent did not perform any rewiring, i.e. are the same communities\n            return 1\n        return old_communities.normalized_mutual_information(new_communities).score\n\n    def get_new_community(self, new_community_structure: List[List[int]]) -> List[int]:\n        \"\"\"\n        Search the community target in the new community structure after\n        deception. As new community target after the action, we consider the\n        community that contains the target node, if this community satisfies\n        the deception constraint, the episode is finished, otherwise not.\n\n        Parameters\n        ----------\n        node_target : int\n            Target node to be hidden from the community\n        new_community_structure : List[List[int]]\n            New community structure after deception\n\n        Returns\n        -------\n        List[int]\n            New community target after deception\n        \"\"\"\n        if new_community_structure is None:\n            # The agent did not perform any rewiring, i.e. are the same communities\n            return self.community_target\n        for community in new_community_structure.communities:\n            if self.node_target in community:\n                return community\n        raise ValueError(\"Community not found\")\n\n    def check_goal(self, new_community: int) -> int:\n        \"\"\"\n        Check if the goal of hiding the target node was achieved\n\n        Parameters\n        ----------\n        new_community : int\n            New community of the target node\n\n        Returns\n        -------\n        int\n            1 if the goal was achieved, 0 otherwise\n        \"\"\"\n        if len(new_community) == 1:\n            return 1\n        # Copy the communities to avoid modifying the original ones\n        new_community_copy = new_community.copy()\n        new_community_copy.remove(self.node_target)\n        old_community_copy = self.community_target.copy()\n        old_community_copy.remove(self.node_target)\n        # Compute the similarity between the new and the old community\n        similarity = self.agent.env.community_similarity(\n            new_community_copy, old_community_copy\n        )\n        del new_community_copy, old_community_copy\n        if similarity <= self.tau:\n            return 1\n        return 0\n\n    ############################################################################\n    #                               LOG                                        #\n    ############################################################################\n    def set_log_dict(self) -> None:\n        self.log_dict = dict()\n\n        for alg in self.evaluation_algs:\n            self.log_dict[alg] = {\n                \"goal\": [],\n                \"nmi\": [],\n                \"time\": [],\n                \"steps\": [],\n                \"target_node\": [],\n                \"community_len\": [],\n            }\n\n        # Add environment parameters to the log dictionaryù\n        self.log_dict[\"env\"] = dict()\n        self.log_dict[\"env\"][\"dataset\"] = self.env_name\n        self.log_dict[\"env\"][\"detection_alg\"] = self.detection_alg\n        self.log_dict[\"env\"][\"beta\"] = self.beta\n        self.log_dict[\"env\"][\"tau\"] = self.tau\n        self.log_dict[\"env\"][\"edge_budget\"] = self.edge_budget\n        self.log_dict[\"env\"][\"max_steps\"] = self.max_steps\n\n        # Add Agent Hyperparameters to the log dictionary\n        self.log_dict[\"Agent\"][\"lr\"] = self.lr\n        self.log_dict[\"Agent\"][\"gamma\"] = self.gamma\n        self.log_dict[\"Agent\"][\"lambda_metric\"] = self.lambda_metric\n        self.log_dict[\"Agent\"][\"alpha_metric\"] = self.alpha_metric\n        self.log_dict[\"Agent\"][\"epsilon_prob\"] = self.epsilon_prob\n\n    def save_metrics(\n        self, alg: str, goal: int, nmi: float, time: float, steps: int\n    ) -> dict:\n        \"\"\"Save the metrics of the algorithm in the log dictionary\"\"\"\n        self.log_dict[alg][\"goal\"].append(goal)\n        self.log_dict[alg][\"nmi\"].append(nmi)\n        self.log_dict[alg][\"time\"].append(time)\n        self.log_dict[alg][\"steps\"].append(steps)\n        self.log_dict[alg][\"target_node\"].append(self.node_target)\n        self.log_dict[alg][\"community_len\"].append(len(self.community_target))\n","metadata":{"id":"rwAhTuYBHXt6","execution":{"iopub.status.busy":"2023-12-01T07:17:32.547327Z","iopub.execute_input":"2023-12-01T07:17:32.548149Z","iopub.status.idle":"2023-12-01T07:17:32.604381Z","shell.execute_reply.started":"2023-12-01T07:17:32.548115Z","shell.execute_reply":"2023-12-01T07:17:32.602818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Community Hiding","metadata":{"id":"7XFYxwkq-dk0"}},{"cell_type":"code","source":"class CommunityHiding:\n    \"\"\"\n    Class to evaluate the performance of the agent in the community hiding task,\n    where the agent has to hide a community from a detection algorithm.\n    Futhermore, it is compared with other baselines algorithms:\n        - Safeness Community Deception\n    \"\"\"\n\n    def __init__(\n        self,\n        agent: Agent,\n        model_path: str,\n        lr: float = HyperParams.LR_EVAL.value,\n        gamma: float = HyperParams.GAMMA_EVAL.value,\n        lambda_metric: float = HyperParams.LAMBDA_EVAL.value,\n        alpha_metric: float = HyperParams.ALPHA_EVAL.value,\n        epsilon_prob: float = HyperParams.EPSILON_EVAL.value,\n        eval_steps: int = HyperParams.STEPS_EVAL.value,\n    ) -> None:\n        self.agent = agent\n        self.original_graph = agent.env.original_graph.copy()\n        self.model_path = model_path\n        self.env_name = agent.env.env_name\n        self.detection_alg = agent.env.detection_alg\n        self.community_target = agent.env.community_target\n\n        # Copy the community structure to avoid modifying the original one\n        self.community_structure = copy.deepcopy(agent.env.original_community_structure)\n        # self.node_target = agent.env.node_target\n\n        self.lr = lr\n        self.gamma = gamma\n        self.lambda_metric = lambda_metric\n        self.alpha_metric = alpha_metric\n        self.epsilon_prob = epsilon_prob\n        self.eval_steps = eval_steps\n\n        self.beta = None\n        self.tau = None\n        self.edge_budget = None\n        self.max_steps = None\n        self.community_edge_budget = None\n\n        self.safeness_obj = None\n        self.modularity_obj = None\n        self.deception_score_obj = None\n\n        self.evaluation_algs = [\"Agent\", \"Safeness\", \"Modularity\"]\n\n        # Use a list to store the beta values already computed, beacuse the\n        # Community Deception algorithms are not influenced by the value of\n        # tau, so we can compute the beta values only once\n        self.beta_values_computed = []\n        # Use a dict to store the results of the Community Deception algorithms\n        # for each beta value\n        self.beta_values_results = dict()\n\n    def set_parameters(self, beta: int, tau: float, reset=True) -> None:\n        \"\"\"Set the environment with the new parameters, for new experiments\n\n        Parameters\n        ----------\n        beta : int\n            In this case beta is the percentage of edges to remove or add\n        tau : float\n            Constraint on the goal achievement\n        \"\"\"\n        self.beta = beta\n        self.tau = tau\n\n        # Set community beta value as key of the dictionary\n        if self.beta not in self.beta_values_results:\n            self.beta_values_results[self.beta] = dict()\n\n        self.agent.env.tau = tau\n        # ! NOTE: It isn't the same beta as the one used in the Node Hiding task\n        # self.agent.env.beta = beta\n        # self.agent.env.set_rewiring_budget()\n\n        # Budget for the whole community, beta percentage of the number of nodes\n        # in the target community\n        # self.community_edge_budget = self.beta\n        self.community_edge_budget = math.ceil(\n           len(self.community_target) * (self.beta / 100)\n        )\n\n        # Set the node budge as the community budget\n        # self.node_edge_budget = self.community_edge_budget\n\n        # We can't call the set_rewiring_budget function because we don't have\n        # the beta value multiplier, and also we need to adapt to the Community\n        # Hiding task, where the budget for the agent is set as the BETA percentage\n        # of all the edges in the graph divided by the number of nodes in the\n        # target community. So we set manually all the values of set_rewiring_budget\n        # function.\n        # self.agent.env.edge_budget = self.node_edge_budget\n        # self.agent.env.max_steps = self.node_edge_budget * HyperParams.MAX_STEPS_MUL.value\n        self.agent.env.used_edge_budget = 0\n        self.agent.env.stop_episode = False\n        self.agent.env.reward = 0\n        self.agent.env.old_rewards = 0\n        self.agent.env.possible_actions = self.agent.env.get_possible_actions()\n        self.agent.env.len_add_actions = len(self.agent.env.possible_actions[\"ADD\"])\n\n        # Initialize the log dictionary\n        if reset:\n            self.set_log_dict()\n\n        self.path_to_save = (\n            FilePaths.TEST_DIR.value\n            + f\"{self.env_name}/{self.detection_alg}/\"\n            + f\"community_hiding/\"\n            + f\"tau_{self.tau}/\"\n            + f\"beta_{self.beta}/\"\n            + f\"eps_{self.epsilon_prob}/\"\n            + f\"lr_{self.lr}/gamma_{self.gamma}/\"\n            + f\"lambda_{self.lambda_metric}/alpha_{self.alpha_metric}/\"\n        )\n\n    def reset_experiment(self) -> None:\n        \"\"\"\n        Reset the environment and the agent at the beginning of each episode,\n        and change the target community and node\n        \"\"\"\n        self.agent.env.change_target_community()\n\n        # Copy the community target to avoid modifying the original one\n        self.community_target = copy.deepcopy(self.agent.env.community_target)\n        # self.node_target = self.agent.env.node_target\n\n        self.set_parameters(self.beta, self.tau, reset=False)\n\n        # Initialize the Deception Score algorithm\n        self.deception_score_obj = DeceptionScore(copy.deepcopy(self.community_target))\n\n        self.safeness_obj = Safeness(\n            self.community_edge_budget,\n            self.original_graph,\n            self.community_target,\n            self.community_structure,\n        )\n\n        self.modularity_obj = Modularity(\n            self.community_edge_budget,\n            self.original_graph,\n            self.community_target,\n            self.community_structure,\n            self.agent.env.detection,\n        )\n\n        # # Compute a Dictionary where the keys are the nodes of the community\n        # # target and the values are the centrality of the nodes\n        # node_centralities = nx.centrality.degree_centrality(self.original_graph)\n        # # Get the subset of the dictionary with only the nodes of the community\n        # node_com_centralities = {k: node_centralities[k] for k in self.community_target}\n        # # Order in descending order the dictionary\n        # self.node_com_centralities = dict(\n        #     sorted(\n        #         node_com_centralities.items(), key=lambda item: item[1], reverse=True\n        #     )\n        # )\n\n        # ! Compute the budget for each node in the target community, for the\n        # function run_agent_distributed_budget()\n        # self.compute_budget_proportionally(self.original_graph, self.community_target)\n\n    def compute_budget_proportionally(\n        self, graph: nx.Graph, community_target: List[int]\n    ) -> None:\n        \"\"\"\n        Compute the budget for each node in the target community, proportionally\n        to the degree of each node.\n\n        Parameters\n        ----------\n        graph : nx.Graph\n            Graph on which the agent is acting\n        community_target : List[int]\n            Target community\n        \"\"\"\n        # Calculate the total degree of all nodes in the graph\n        total_degree = sum(dict(graph.degree()).values())\n        remaining_budget = self.community_edge_budget\n        self.budget_per_node = {}\n\n        if total_degree == 0:\n            # Divide the budget equally between all nodes\n            budget_per_node = self.community_edge_budget // len(community_target)\n            self.budget_per_node = {node: budget_per_node for node in community_target}\n            return\n\n        # Order the nodes in descending order based on their degree\n        sorted_nodes = sorted(\n            community_target, key=lambda node: graph.degree(node), reverse=True\n        )\n\n        for node in sorted_nodes:\n            degree = graph.degree(node)\n            proportion = degree / total_degree\n            new_budget = min(\n                self.community_edge_budget,\n                math.ceil(self.community_edge_budget * proportion),\n            )\n            self.budget_per_node[node] = new_budget\n            remaining_budget -= new_budget\n\n    def run_experiment(self) -> None:\n        # Start evaluation\n        preferred_size_list = HyperParams.PREFERRED_COMMUNITY_SIZE.value\n        sizes = trange(\n            len(preferred_size_list), desc=\"* * * Community Size\", leave=True\n        )\n        for i in sizes:\n            self.agent.env.set_preferred_community_size(preferred_size_list[i])\n            compute_baselines = True\n            self.reset_experiment()\n\n            # Print community size in tqdm\n            sizes.set_description(f\"* * * Community Size: {len(self.community_target)}\")\n\n            steps = trange(self.eval_steps, desc=\"* * * * Testing Episode\", leave=False)\n            for step in steps:\n                self.compute_budget_proportionally(\n                    self.original_graph, self.community_target\n                )\n                # ° ------ Agent Rewiring ------ ° #\n                steps.set_description(\n                    f\"* * * * Testing Episode {step+1} | Agent Rewiring\"\n                )\n                # self.run_alg(self.run_agent)\n                self.run_alg(self.run_agent_distributed_budget)\n\n                # ° --------- Baselines --------- ° #\n                if compute_baselines:\n                    # Safeness, it is computed only once because it is deterministic\n                    steps.set_description(\n                        f\"* * * * Testing Episode {step+1} | Safeness Rewiring\"\n                    )\n                    self.run_alg(self.run_safeness)\n                    compute_baselines = False\n\n                    # Modularity, it is computed at each step because the edge deletion\n                    # is not deterministic\n                    steps.set_description(\n                        f\"* * * * Testing Episode {step+1} | Modularity Rewiring\"\n                    )\n                    self.run_alg(self.run_modularity)\n\n        Utils.check_dir(self.path_to_save)\n        Utils.save_test(\n            log=self.log_dict,\n            files_path=self.path_to_save,\n            log_name=\"evaluation_community_hiding\",\n            algs=self.evaluation_algs,\n            metrics=[\"nmi\", \"goal\", \"deception_score\", \"time\", \"steps\"],\n        )\n\n    def run_alg(self, function: Callable) -> None:\n        \"\"\"\n        Wrapper function to run the evaluation of a generic algorithm\n\n        Parameters\n        ----------\n        function : Callable\n            Algorithm to evaluate\n        \"\"\"\n        start = time.time()\n        alg_name, goal, nmi, deception_score, step = function()\n        end = time.time() - start\n        # Save results in the log dictionary\n        self.save_metrics(alg_name, goal, nmi, deception_score, end, step)\n\n    ############################################################################\n    #                               AGENT                                      #\n    ############################################################################\n    def run_agent(self) -> Tuple[str, int, float, float, int]:\n        \"\"\"\n        Evaluate the agent on the Node Hiding task. In this case the agent starts\n        to hide the node with the highest centrality in the target community, and\n        with the budget equal to the Community Deception baselines, and it is\n        scaled down at each step, based on the number of steps performed.\n\n        Returns\n        -------\n        Tuple[str, nx.Graph, int, float, int]\n            Algorithm name, goal, nmi, deception score, steps\n        \"\"\"\n        tot_steps = 0\n        agent_goal_reached = False\n        # Initialize the new community structure as the original one, because\n        # the agent could not perform any rewiring\n        communities = self.community_structure\n        # As first node to hide, we choose the node with the highest centrality\n        # in the target community\n        node = self.node_com_centralities.popitem()[0]\n        while True:\n            self.agent.env.node_target = node\n            # The agent possible action are changed in the test function, which\n            # calls the reset function of the environment\n            new_graph = self.agent.test(\n                lr=self.lr,\n                gamma=self.gamma,\n                lambda_metric=self.lambda_metric,\n                alpha_metric=self.alpha_metric,\n                epsilon_prob=self.epsilon_prob,\n                model_path=self.model_path,\n            )\n            # Get the new community structure\n            self.agent.env.new_community_structure = (\n                self.agent.env.detection.compute_community(new_graph)\n            )\n            new_communities = self.agent.env.new_community_structure\n            # Check if the agent performed any rewiring\n            if new_communities is None:\n                new_communities = communities\n            # Get the community in the new community structure, which contains\n            # the highest number of nodes of the target community\n            new_community = max(\n                new_communities.communities,\n                key=lambda c: sum(1 for n in self.community_target if n in c),\n            )\n            # Recompute the node centralities after the rewiring\n            node_centralities = nx.centrality.degree_centrality(new_graph)\n            # Choose the next node to hide, as the node with the highest\n            # centrality in the new community\n            if self.agent.env.used_edge_budget > 0:\n                # If the agent has not performed all the rewiring actions\n                node = max(\n                    (n for n in new_community if n in self.community_target),\n                    key=lambda n: node_centralities[n],\n                )\n            tot_steps += self.agent.env.used_edge_budget\n            # Reduce the edge budget\n            self.agent.env.edge_budget = self.node_edge_budget - tot_steps\n            self.agent.env.max_steps = (\n                self.agent.env.edge_budget * HyperParams.MAX_STEPS_MUL.value\n            )\n            # Check if the agent reached the goal\n            if tot_steps >= self.community_edge_budget or node is None:\n                if self.agent.env.new_community_structure is None:\n                    # The agent did not perform any rewiring, i.e. are the same communities\n                    agent_goal_reached = False\n                    break\n                if (\n                    self.community_target\n                    not in self.agent.env.new_community_structure.communities\n                ):\n                    agent_goal_reached = True\n                communities = self.agent.env.new_community_structure\n                break\n\n        # Compute Deception Score between the new community structure and the\n        # original one\n        deception_score = self.deception_score_obj.get_deception_score(\n            new_graph.copy(),\n            copy.deepcopy(communities.communities),\n        )\n        # Compute NMI between the new community structure and the original one\n        nmi = self.get_nmi(\n            self.community_structure, self.agent.env.new_community_structure\n        )\n        goal = 1 if agent_goal_reached else 0\n        return self.evaluation_algs[0], goal, nmi, deception_score, tot_steps\n\n    def run_agent_distributed_budget(self) -> Tuple[str, int, float, float, int]:\n        \"\"\"\n        Evaluate the agent on the Node Hiding task. In this case the budget is\n        distributed proportionally to the degree of each node in the target\n        community, and the agent starts to hide the node with the highest budget.\n\n        Returns\n        -------\n        Tuple[str, nx.Graph, int, float, int]\n            Algorithm name, goal, nmi, deception score, steps\n        \"\"\"\n        tot_steps = 0\n        agent_goal_reached = False\n        # Choose the node from the target community with the highest budget\n        node = max(\n            self.community_target, key=lambda n: self.budget_per_node[n], default=None\n        )\n\n        if node is None:\n            print(self.budget_per_node)\n            print(self.community_edge_budget)\n            for node in self.community_target:\n                print(node, self.original_graph.degree(node))\n            raise Exception(\"Node is None\")\n\n        while True:\n            self.agent.env.node_target = node\n            # Set the agent edge budget as the budget of the node\n            self.agent.env.edge_budget = self.budget_per_node[node]\n            # Set Max Steps as the budget of the node multiplied by a constant\n            self.agent.env.max_steps = (\n                self.community_edge_budget * HyperParams.MAX_STEPS_MUL.value\n            )\n            # The agent possible action are changed in the test function, which\n            # calls the reset function of the environment\n            new_graph = self.agent.test(\n                lr=self.lr,\n                gamma=self.gamma,\n                lambda_metric=self.lambda_metric,\n                alpha_metric=self.alpha_metric,\n                epsilon_prob=self.epsilon_prob,\n                model_path=self.model_path,\n            )\n\n            # TEST: decrease the budget of the node\n            self.budget_per_node[node] -= self.agent.env.used_edge_budget\n            node = max(\n                # (n for n in self.community_target if n in new_community),\n                (n for n in self.community_target),\n                key=lambda n: self.budget_per_node[n],\n                default=None,\n            )\n            # Increment the total steps\n            tot_steps += self.agent.env.used_edge_budget\n\n            if tot_steps >= self.community_edge_budget or node is None:\n                break\n\n        # Compute new community structure\n        self.agent.env.new_community_structure = (\n            self.agent.env.detection.compute_community(new_graph)\n        )\n\n        if (\n            self.community_structure\n            not in self.agent.env.new_community_structure.communities\n        ):\n            agent_goal_reached = True\n        # Compute Deception Score between the new community structure and the\n        # original one\n        deception_score = self.deception_score_obj.get_deception_score(\n            new_graph.copy(),\n            copy.deepcopy(self.agent.env.new_community_structure.communities),\n        )\n        # Compute NMI between the new community structure and the original one\n        nmi = self.get_nmi(\n            self.community_structure, self.agent.env.new_community_structure\n        )\n        goal = 1 if agent_goal_reached else 0\n        return self.evaluation_algs[0], goal, nmi, deception_score, tot_steps\n\n    ############################################################################\n    #                               BASELINES                                  #\n    ############################################################################\n    def run_safeness(self) -> Tuple[str, int, float, float, int]:\n        \"\"\"\n        Evaluate the Safeness algorithm on the Node Hiding task\n\n        Returns\n        -------\n        Tuple[str, nx.Graph, int, float, int]\n            Algorithm name, goal, nmi, deception score, steps\n        \"\"\"\n        new_graph, steps = self.safeness_obj.run()\n\n        # Compute the new community structure\n        new_communities = self.agent.env.detection.compute_community(new_graph)\n\n        # Compute Deception Score between the new community structure and the\n        # original one\n        deception_score = self.deception_score_obj.get_deception_score(\n            new_graph.copy(),\n            copy.deepcopy(new_communities.communities),\n        )\n        # Compute NMI between the new community structure and the original one\n        nmi = self.get_nmi(self.community_structure, new_communities)\n        goal = 1 if self.community_target not in new_communities.communities else 0\n        return self.evaluation_algs[1], goal, nmi, deception_score, steps\n\n    def run_modularity(self) -> Tuple[str, int, float, float, int]:\n        \"\"\"\n        Evaluate the Safeness algorithm on the Node Hiding task\n\n        Returns\n        -------\n        Tuple[str, nx.Graph, int, float, int]\n            Algorithm name, goal, nmi, deception score, steps\n        \"\"\"\n        new_graph, steps, new_communities = self.modularity_obj.run()\n\n        # Compute Deception Score between the new community structure and the\n        # original one\n        deception_score = self.deception_score_obj.get_deception_score(\n            new_graph.copy(),\n            copy.deepcopy(new_communities.communities),\n        )\n        # print(\"Deception Score:\", deception_score)\n        # Compute NMI between the new community structure and the original one\n        nmi = self.get_nmi(self.community_structure, new_communities)\n        goal = 1 if self.community_target not in new_communities.communities else 0\n        return self.evaluation_algs[2], goal, nmi, deception_score, steps\n\n    ############################################################################\n    #                               UTILS                                      #\n    ############################################################################\n    def get_nmi(\n        self,\n        old_communities: cdlib.NodeClustering,\n        new_communities: cdlib.NodeClustering,\n    ) -> float:\n        \"\"\"\n        Compute the Normalized Mutual Information between the old and the new\n        community structure\n\n        Parameters\n        ----------\n        old_communities : cdlib.NodeClustering\n            Community structure before deception\n        new_communities : cdlib.NodeClustering\n            Community structure after deception\n\n        Returns\n        -------\n        float\n            Normalized Mutual Information between the old and the new community\n        \"\"\"\n        if new_communities is None:\n            # The agent did not perform any rewiring, i.e. are the same communities\n            return 1\n        return old_communities.normalized_mutual_information(new_communities).score\n\n    ############################################################################\n    #                               LOG                                        #\n    ############################################################################\n    def set_log_dict(self) -> None:\n        self.log_dict = dict()\n\n        for alg in self.evaluation_algs:\n            self.log_dict[alg] = {\n                \"goal\": [],\n                \"nmi\": [],\n                \"time\": [],\n                \"deception_score\": [],\n                \"steps\": [],\n                \"community_len\": [],\n            }\n\n        # Add environment parameters to the log dictionaryù\n        self.log_dict[\"env\"] = dict()\n        self.log_dict[\"env\"][\"dataset\"] = self.env_name\n        self.log_dict[\"env\"][\"detection_alg\"] = self.detection_alg\n        self.log_dict[\"env\"][\"beta\"] = self.beta\n        self.log_dict[\"env\"][\"tau\"] = self.tau\n        self.log_dict[\"env\"][\"edge_budget\"] = self.edge_budget\n        self.log_dict[\"env\"][\"max_steps\"] = self.max_steps\n\n        # Add Agent Hyperparameters to the log dictionary\n        self.log_dict[\"Agent\"][\"lr\"] = self.lr\n        self.log_dict[\"Agent\"][\"gamma\"] = self.gamma\n        self.log_dict[\"Agent\"][\"lambda_metric\"] = self.lambda_metric\n        self.log_dict[\"Agent\"][\"alpha_metric\"] = self.alpha_metric\n        self.log_dict[\"Agent\"][\"epsilon_prob\"] = self.epsilon_prob\n\n    def save_metrics(\n        self,\n        alg: str,\n        goal: int,\n        nmi: float,\n        deception_score: float,\n        time: float,\n        steps: int,\n    ) -> dict:\n        \"\"\"Save the metrics of the algorithm in the log dictionary\"\"\"\n        self.log_dict[alg][\"goal\"].append(goal)\n        self.log_dict[alg][\"nmi\"].append(nmi)\n        self.log_dict[alg][\"deception_score\"].append(deception_score)\n        self.log_dict[alg][\"time\"].append(time)\n        self.log_dict[alg][\"steps\"].append(steps)\n        self.log_dict[alg][\"community_len\"].append(len(self.community_target))\n","metadata":{"id":"8BuSKrAE-dk0","execution":{"iopub.status.busy":"2023-12-01T07:17:32.633908Z","iopub.execute_input":"2023-12-01T07:17:32.634366Z","iopub.status.idle":"2023-12-01T07:17:32.715584Z","shell.execute_reply.started":"2023-12-01T07:17:32.634333Z","shell.execute_reply":"2023-12-01T07:17:32.714399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Execution","metadata":{"id":"Pnf9azpI4qN6"}},{"cell_type":"code","source":"# Create paths if not exist\nUtils.check_dir(FilePaths.LOG_DIR.value)\nUtils.check_dir(FilePaths.TEST_DIR.value)","metadata":{"id":"BSkNI2Z3Kz3s","execution":{"iopub.status.busy":"2023-12-01T07:17:32.718078Z","iopub.execute_input":"2023-12-01T07:17:32.718420Z","iopub.status.idle":"2023-12-01T07:17:32.730017Z","shell.execute_reply.started":"2023-12-01T07:17:32.718391Z","shell.execute_reply":"2023-12-01T07:17:32.729023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = FilePaths.TRAINED_MODEL.value\ndatasets = [\n    FilePaths.ASTR.value,\n    # FilePaths.FB_75.value,\n    # FilePaths.POW.value,\n    # FilePaths.KAR.value,\n    # FilePaths.WORDS.value,\n    # FilePaths.VOTE.value,\n    # FilePaths.NETS.value,\n    ]\ndetection_algs = [\n    DetectionAlgorithmsNames.GRE.value,\n    # DetectionAlgorithmsNames.LOUV.value,\n    # DetectionAlgorithmsNames.WALK.value,\n    ]\n\n# Tau defines the strength of the constraint on the goal achievement\ntaus = [0.3] #, 0.5, 0.8]\n# BETAs defines the number of actions to perform\n# Beta for the community hiding task defines the percentage of rewiring\n# action, add or remove edges\ncommunity_betas = [1]#, 3, 5, 10]\n# Beta for the node hiding task is a multiplier of mean degree of the\n# the graph\nnode_betas = [1, 3, 5, 10]  # [5, 10, 15, 20]\n\nprint(\"* NOTE:\")\nprint(\"*    - Beta for Node Hiding is a multiplier of the mean degree of the graph\")\nprint(\"*    - Beta for Community Hiding is the percentage of rewiring action, add or remove edges\")\n\nfor dataset in datasets:\n\n    print(\"* Dataset:\", dataset)\n    # ° --- Environment Setup --- ° #\n    env = GraphEnvironment(graph_path=dataset)\n\n    # ° ------  Agent Setup ----- ° #\n    agent = Agent(env=env)\n\n    for alg in detection_algs:\n        print(\"* Detection Algorithm:\", alg)\n        agent.env.set_communities(alg)\n\n        # ° ------ TEST ------ ° #\n        # Initialize the test class\n        node_hiding = NodeHiding(agent=agent, model_path=model_path)\n        community_hiding = CommunityHiding(agent=agent, model_path=model_path)\n\n        print(\"* NOTE:\")\n        print(\"*    - Beta for Node Hiding is a multiplier of the mean degree of the graph\")\n        print(\"*    - Beta for Community Hiding is the percentage of rewiring action, add or remove edges\")\n        \"\"\"\n        for tau in taus:\n            print(\"* Node Hiding with tau = {}\".format(tau))\n            for beta in node_betas:\n                print(\"* * Beta Node = {}\".format(beta))\n                node_hiding.set_parameters(beta=beta, tau=tau)\n                node_hiding.run_experiment()\n        \"\"\"\n        print(\"* Community Hiding with tau = {}\".format(0.3))\n        for beta in community_betas:\n            print(\"* * Beta Community = {}\".format(beta))\n            community_hiding.set_parameters(beta=beta, tau=0.3)\n            community_hiding.run_experiment()\n        print(\"* \"*50)\n        \n\n    del agent, env, community_hiding, node_hiding","metadata":{"id":"wKP3Qy24P7OT","scrolled":true,"outputId":"5e7cd00a-0a05-406d-fdf1-329a393b64d9","execution":{"iopub.status.busy":"2023-12-01T07:17:32.731495Z","iopub.execute_input":"2023-12-01T07:17:32.731990Z","iopub.status.idle":"2023-12-01T07:19:17.386644Z","shell.execute_reply.started":"2023-12-01T07:17:32.731957Z","shell.execute_reply":"2023-12-01T07:19:17.385010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r file.zip /kaggle/working","metadata":{"id":"ixFpogfjKz3s","scrolled":true,"execution":{"iopub.status.busy":"2023-12-01T07:19:17.387779Z","iopub.status.idle":"2023-12-01T07:19:17.388296Z","shell.execute_reply.started":"2023-12-01T07:19:17.388053Z","shell.execute_reply":"2023-12-01T07:19:17.388075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n# FileLink(r'file.zip')","metadata":{"id":"CrKGZTuYKz3t","execution":{"iopub.status.busy":"2023-12-01T07:19:17.389712Z","iopub.status.idle":"2023-12-01T07:19:17.390157Z","shell.execute_reply.started":"2023-12-01T07:19:17.389943Z","shell.execute_reply":"2023-12-01T07:19:17.389964Z"},"trusted":true},"execution_count":null,"outputs":[]}]}